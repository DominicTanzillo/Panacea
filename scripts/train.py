# Generated by Claude Code -- 2026-02-08
"""Train and evaluate all conjunction prediction models."""

import sys
import json
import numpy as np
from pathlib import Path

# Add project root to path
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from src.data.cdm_loader import load_dataset, build_events, events_to_flat_features
from src.model.baseline import OrbitalShellBaseline
from src.model.classical import XGBoostConjunctionModel
from src.evaluation.metrics import full_evaluation

DATA_DIR = ROOT / "data" / "cdm"
MODEL_DIR = ROOT / "models"
RESULTS_DIR = ROOT / "results"


def train_baseline(events_train, events_test):
    """Train and evaluate the orbital shell density baseline."""
    print("\n" + "=" * 60)
    print("  MODEL 1: Orbital Shell Density Baseline")
    print("=" * 60)

    # Extract altitudes and labels
    altitudes_train = np.array([e.altitude_km for e in events_train])
    y_risk_train = np.array([e.risk_label for e in events_train])
    y_miss_train = np.array([np.log1p(e.final_miss_distance) for e in events_train])

    altitudes_test = np.array([e.altitude_km for e in events_test])
    y_risk_test = np.array([e.risk_label for e in events_test])
    y_miss_test = np.array([np.log1p(e.final_miss_distance) for e in events_test])

    model = OrbitalShellBaseline(bin_width_km=50.0)
    model.fit(altitudes_train, y_risk_train, y_miss_train)

    # Predict
    risk_preds, miss_preds = model.predict(altitudes_test)

    # Evaluate
    results = full_evaluation(
        "Orbital Shell Baseline",
        y_risk_test, risk_preds,
        y_miss_test, miss_preds,
    )

    # Save model
    model.save(MODEL_DIR / "baseline.json")

    return results


def train_xgboost(events_train, events_test):
    """Train and evaluate XGBoost on engineered features."""
    print("\n" + "=" * 60)
    print("  MODEL 2: XGBoost on Engineered Features")
    print("=" * 60)

    # Build flat feature vectors
    print("Engineering features ...")
    X_train, y_risk_train, y_miss_train = events_to_flat_features(events_train)
    X_test, y_risk_test, y_miss_test = events_to_flat_features(events_test)

    print(f"Feature matrix: {X_train.shape[1]} features")
    print(f"Train: {X_train.shape[0]} events | Test: {X_test.shape[0]} events")

    # Split off validation from training (last 10%)
    n_val = int(len(X_train) * 0.1)
    X_val, y_risk_val, y_miss_val = X_train[-n_val:], y_risk_train[-n_val:], y_miss_train[-n_val:]
    X_train_sub = X_train[:-n_val]
    y_risk_train_sub = y_risk_train[:-n_val]
    y_miss_train_sub = y_miss_train[:-n_val]

    model = XGBoostConjunctionModel()
    model.fit(
        X_train_sub, y_risk_train_sub, y_miss_train_sub,
        X_val, y_risk_val, y_miss_val,
    )

    # Predict on test
    risk_probs, miss_km = model.predict(X_test)
    miss_log_pred = np.log1p(miss_km)

    # Evaluate
    results = full_evaluation(
        "XGBoost (Engineered Features)",
        y_risk_test, risk_probs,
        y_miss_test, miss_log_pred,
    )

    # Feature importance (top 20)
    importances = model.risk_classifier.feature_importances_
    top_idx = np.argsort(importances)[::-1][:20]
    print("\nTop 20 risk features by importance:")
    for i, idx in enumerate(top_idx):
        print(f"  {i+1:2d}. Feature {idx:3d}: {importances[idx]:.4f}")

    # Save model
    model.save(MODEL_DIR / "xgboost.pkl")

    return results


def main():
    MODEL_DIR.mkdir(parents=True, exist_ok=True)
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    # Load data
    print("Loading CDM dataset ...")
    train_df, test_df = load_dataset(DATA_DIR)

    # Build event objects
    print("\nBuilding conjunction events from training data ...")
    events_train = build_events(train_df)

    print("\nBuilding conjunction events from test data ...")
    events_test = build_events(test_df)

    # Train models
    all_results = []

    baseline_results = train_baseline(events_train, events_test)
    all_results.append(baseline_results)

    xgb_results = train_xgboost(events_train, events_test)
    all_results.append(xgb_results)

    # Save all results
    results_path = RESULTS_DIR / "model_comparison.json"
    with open(results_path, "w") as f:
        json.dump(all_results, f, indent=2)
    print(f"\nResults saved to {results_path}")

    # Summary table
    print("\n" + "=" * 80)
    print(f"{'Model':<35} {'AUC-PR':>8} {'AUC-ROC':>8} {'F1':>6} {'MAE(log)':>9} {'MAE(km)':>9}")
    print("-" * 80)
    for r in all_results:
        print(f"{r['model']:<35} {r['auc_pr']:>8.4f} {r['auc_roc']:>8.4f} "
              f"{r['f1']:>6.4f} {r['mae_log']:>9.4f} {r['mae_km']:>9.2f}")
    print("=" * 80)


if __name__ == "__main__":
    main()
