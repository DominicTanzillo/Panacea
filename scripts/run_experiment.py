# Generated by Claude Code -- 2026-02-13
"""Run staleness sensitivity experiment across all 3 models.

Usage:
    python scripts/run_experiment.py              # Full experiment (8 cutoffs)
    python scripts/run_experiment.py --quick       # Quick test (3 cutoffs)
"""

import sys
import json
import argparse
import torch
from pathlib import Path

ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from src.data.cdm_loader import load_dataset, get_feature_columns
from src.data.sequence_builder import CDMSequenceDataset
from src.model.baseline import OrbitalShellBaseline
from src.model.classical import XGBoostConjunctionModel
from src.model.deep import PhysicsInformedTFT
from src.evaluation.staleness import (
    run_staleness_experiment,
    DEFAULT_CUTOFFS,
    QUICK_CUTOFFS,
)


def load_pitft_model(model_path: Path, device: torch.device):
    """Load PI-TFT from checkpoint, reconstructing from config."""
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    config = checkpoint["config"]

    model = PhysicsInformedTFT(
        n_temporal_features=config["n_temporal"],
        n_static_features=config["n_static"],
        d_model=config.get("d_model", 128),
        n_heads=config.get("n_heads", 4),
        n_layers=config.get("n_layers", 2),
    ).to(device)

    model.load_state_dict(checkpoint["model_state"])
    model.eval()
    return model, checkpoint


def main():
    parser = argparse.ArgumentParser(description="Run staleness sensitivity experiment")
    parser.add_argument("--quick", action="store_true", help="Quick test (3 cutoffs)")
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")

    data_dir = ROOT / "data" / "cdm"
    model_dir = ROOT / "models"
    results_dir = ROOT / "results"
    results_dir.mkdir(parents=True, exist_ok=True)

    cutoffs = QUICK_CUTOFFS if args.quick else DEFAULT_CUTOFFS
    print(f"Cutoffs: {cutoffs}")

    # Load data
    print("\nLoading CDM dataset ...")
    train_df, test_df = load_dataset(data_dir)
    feature_cols = get_feature_columns(train_df)

    # Load models first (need checkpoint columns for dataset)
    print("\nLoading models ...")
    baseline = OrbitalShellBaseline.load(model_dir / "baseline.json")
    print("  Baseline loaded")

    xgboost = XGBoostConjunctionModel.load(model_dir / "xgboost.pkl")
    print("  XGBoost loaded")

    pitft_model = None
    pitft_checkpoint = None
    pitft_path = model_dir / "transformer.pt"
    if pitft_path.exists():
        pitft_model, pitft_checkpoint = load_pitft_model(pitft_path, device)
        temp = pitft_checkpoint.get("temperature", 1.0)
        print(f"  PI-TFT loaded (epoch {pitft_checkpoint['epoch']}, T={temp:.3f})")
    else:
        print("  PI-TFT checkpoint not found, skipping")

    # Build training dataset for normalization stats
    # Use checkpoint's column names to ensure dimensionality match
    print("\nBuilding training dataset (for normalization) ...")
    temporal_cols = None
    static_cols = None
    if pitft_checkpoint:
        temporal_cols = pitft_checkpoint.get("temporal_cols")
        static_cols = pitft_checkpoint.get("static_cols")

    # Pad missing columns in train_df
    train_df_padded = train_df.copy()
    if temporal_cols:
        for col in temporal_cols:
            if col not in train_df_padded.columns:
                train_df_padded[col] = 0.0
    if static_cols:
        for col in static_cols:
            if col not in train_df_padded.columns:
                train_df_padded[col] = 0.0

    train_ds = CDMSequenceDataset(
        train_df_padded,
        temporal_cols=temporal_cols,
        static_cols=static_cols,
    )

    # Run experiment
    print(f"\n{'='*60}")
    print(f"  Running staleness experiment ({len(cutoffs)} cutoffs)")
    print(f"{'='*60}")

    results = run_staleness_experiment(
        baseline_model=baseline,
        xgboost_model=xgboost,
        pitft_model=pitft_model,
        pitft_checkpoint=pitft_checkpoint,
        test_df=test_df,
        train_ds=train_ds,
        feature_cols=feature_cols,
        device=device,
        cutoffs=cutoffs,
    )

    # Save results
    output_path = results_dir / "staleness_experiment.json"
    with open(output_path, "w") as f:
        json.dump(results, f, indent=2, default=str)
    print(f"\nResults saved to {output_path}")

    # Print summary
    print(f"\n{'='*60}")
    print(f"  STALENESS EXPERIMENT SUMMARY")
    print(f"{'='*60}")
    print(f"{'Cutoff':>8s} | {'Baseline':>10s} | {'XGBoost':>10s} | {'PI-TFT':>10s}")
    print(f"{'-'*8}-+-{'-'*10}-+-{'-'*10}-+-{'-'*10}")
    for i, cutoff in enumerate(cutoffs):
        b_auc = results["baseline"][i].get("auc_pr", 0)
        x_auc = results["xgboost"][i].get("auc_pr", 0)
        p_auc = results["pitft"][i].get("auc_pr", 0)
        print(f"{cutoff:8.3f} | {b_auc:10.4f} | {x_auc:10.4f} | {p_auc:10.4f}")


if __name__ == "__main__":
    main()
