# Generated by Claude Code -- 2026-02-13
"""Weekly PI-TFT fine-tuning from accumulated prediction outcomes.

Designed to run as a GitHub Actions cron job (weekly, Sunday).
Downloads current model from HuggingFace, fine-tunes on new outcome data
from Firebase, uploads improved model back.

Safety guardrails:
  - Won't fine-tune unless MIN_NEW_OUTCOMES new labeled examples exist
  - Max 5 epochs to keep runtime under 15 minutes on CPU
  - Very low learning rate (1e-5) to prevent catastrophic forgetting
  - Saves old model as fallback before overwriting
  - Validates on held-out split; reverts if performance degrades

Usage:
    python scripts/weekly_finetune.py                  # Full run
    python scripts/weekly_finetune.py --dry-run        # Check data, don't train
    python scripts/weekly_finetune.py --local-only     # Skip Firebase, use local logs
"""

import sys
import os
import json
import time
import argparse
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from datetime import datetime, timezone

ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from src.model.deep import PhysicsInformedTFT, SigmoidFocalLoss
from src.data.sequence_builder import (
    CDMSequenceDataset,
    TEMPORAL_FEATURES,
    STATIC_FEATURES,
    MAX_SEQ_LEN,
)
from src.evaluation.metrics import evaluate_risk

# --- Safety guardrails ---
MIN_NEW_OUTCOMES = 20       # Don't fine-tune with fewer than this
MAX_EPOCHS = 5              # Cap epochs to keep runtime short
MAX_TRAINING_MINUTES = 12   # Hard time limit
FINETUNE_LR = 1e-5          # Very small LR for fine-tuning
BATCH_SIZE = 32             # Small batch for CPU memory
VAL_FRACTION = 0.2          # Hold out 20% for validation
MIN_AUC_PR_RATIO = 0.90     # Revert if new AUC-PR < 90% of old

MODEL_DIR = ROOT / "models"
LOG_DIR = ROOT / "data" / "prediction_logs"


def load_outcomes_from_firebase() -> list[dict]:
    """Pull prediction outcomes from Firebase Firestore."""
    sa_json = os.environ.get("FIREBASE_SERVICE_ACCOUNT", "")
    if not sa_json:
        print("  No FIREBASE_SERVICE_ACCOUNT — cannot pull from Firebase")
        return []

    try:
        from google.cloud.firestore import Client as FirestoreClient
        from google.oauth2.service_account import Credentials

        sa_info = json.loads(sa_json)
        creds = Credentials.from_service_account_info(sa_info)
        project_id = sa_info.get("project_id", "")
        db = FirestoreClient(project=project_id, credentials=creds)

        outcomes = []
        # Query all outcome documents
        for date_doc in db.collection("outcomes").stream():
            for result_doc in date_doc.reference.collection("results").stream():
                outcome = result_doc.to_dict()
                outcomes.append(outcome)

        print(f"  Pulled {len(outcomes)} outcomes from Firebase")
        return outcomes

    except Exception as e:
        print(f"  Firebase pull failed: {e}")
        return []


def load_outcomes_from_local() -> list[dict]:
    """Load prediction outcomes from local JSONL files."""
    outcomes = []
    for f in sorted(LOG_DIR.glob("*_outcomes.jsonl")):
        with open(f) as fh:
            for line in fh:
                line = line.strip()
                if line:
                    outcomes.append(json.loads(line))
    print(f"  Loaded {len(outcomes)} outcomes from local files")
    return outcomes


def outcomes_to_training_data(outcomes: list[dict]) -> list[dict]:
    """Convert outcome records into training examples.

    Each outcome has sat1/sat2 info and whether either maneuvered.
    We create a labeled example: maneuvered = high risk (positive).
    """
    examples = []
    seen = set()

    for outcome in outcomes:
        # Deduplicate by sat pair + date
        key = (
            outcome.get("sat1_norad", 0),
            outcome.get("sat2_norad", 0),
            outcome.get("prediction_date", ""),
        )
        if key in seen:
            continue
        seen.add(key)

        either_maneuvered = outcome.get("either_maneuvered", False)
        risk_label = 1.0 if either_maneuvered else 0.0

        examples.append({
            "risk_label": risk_label,
            "predicted_risk": outcome.get("predicted_risk", 0.0),
            "sat1_norad": outcome.get("sat1_norad", 0),
            "sat2_norad": outcome.get("sat2_norad", 0),
            "sat1_delta_a_m": outcome.get("sat1_delta_a_m", 0.0),
            "sat2_delta_a_m": outcome.get("sat2_delta_a_m", 0.0),
        })

    n_pos = sum(1 for e in examples if e["risk_label"] > 0)
    print(f"  Training examples: {len(examples)} ({n_pos} positive)")
    return examples


def load_model(device: torch.device):
    """Load PI-TFT model from local checkpoint or HuggingFace."""
    model_path = MODEL_DIR / "transformer.pt"

    # Try HuggingFace first if local doesn't exist
    if not model_path.exists():
        try:
            from huggingface_hub import hf_hub_download
            hf_token = os.environ.get("HF_TOKEN", "")
            downloaded = hf_hub_download(
                repo_id="DominicTanzillo/panacea-models",
                filename="transformer.pt",
                token=hf_token or None,
                local_dir=str(MODEL_DIR),
            )
            print(f"  Downloaded model from HuggingFace: {downloaded}")
        except Exception as e:
            print(f"  HuggingFace download failed: {e}")
            return None, None

    if not model_path.exists():
        print("  No model checkpoint found")
        return None, None

    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    config = checkpoint["config"]

    model = PhysicsInformedTFT(
        n_temporal_features=config["n_temporal"],
        n_static_features=config["n_static"],
        d_model=config.get("d_model", 128),
        n_heads=config.get("n_heads", 4),
        n_layers=config.get("n_layers", 2),
    ).to(device)

    model.load_state_dict(checkpoint["model_state"])
    temp = checkpoint.get("temperature", 1.0)
    print(f"  Loaded PI-TFT (epoch {checkpoint['epoch']}, T={temp:.3f})")

    return model, checkpoint


def finetune_on_outcomes(
    model: PhysicsInformedTFT,
    checkpoint: dict,
    train_ds: CDMSequenceDataset,
    val_ds: CDMSequenceDataset,
    device: torch.device,
    max_epochs: int = MAX_EPOCHS,
    lr: float = FINETUNE_LR,
) -> dict:
    """Fine-tune PI-TFT on new outcome data.

    Returns dict with training metrics and whether to keep the new model.
    """
    temperature = checkpoint.get("temperature", 1.0)
    start_time = time.time()

    # Evaluate baseline performance before fine-tuning
    print("\n  Evaluating pre-finetune performance ...")
    pre_metrics = evaluate_model(model, val_ds, device, temperature)
    print(f"    Pre-finetune AUC-PR: {pre_metrics.get('auc_pr', 0):.4f}")

    # Set up training
    model.train()
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    loss_fn = SigmoidFocalLoss(alpha=0.75, gamma=2.0)
    miss_loss_fn = nn.MSELoss()

    train_loader = torch.utils.data.DataLoader(
        train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,
    )

    best_val_auc = pre_metrics.get("auc_pr", 0)
    best_state = None
    patience = 2
    patience_counter = 0

    for epoch in range(1, max_epochs + 1):
        # Check time limit
        elapsed_min = (time.time() - start_time) / 60
        if elapsed_min > MAX_TRAINING_MINUTES:
            print(f"\n  Time limit reached ({elapsed_min:.1f} min) — stopping")
            break

        model.train()
        epoch_loss = 0.0
        n_batches = 0

        for batch in train_loader:
            temporal = batch["temporal"].to(device)
            static = batch["static"].to(device)
            tca = batch["time_to_tca"].to(device)
            mask = batch["mask"].to(device)
            risk_target = batch["risk_label"].to(device)
            miss_target = batch["miss_log"].to(device)

            risk_logit, miss_pred, _ = model(temporal, static, tca, mask)

            risk_loss = loss_fn(risk_logit.squeeze(-1), risk_target)
            miss_loss = miss_loss_fn(miss_pred.squeeze(-1), miss_target)
            loss = risk_loss + 0.1 * miss_loss

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            epoch_loss += loss.item()
            n_batches += 1

        avg_loss = epoch_loss / max(n_batches, 1)

        # Validate
        model.eval()
        val_metrics = evaluate_model(model, val_ds, device, temperature)
        val_auc = val_metrics.get("auc_pr", 0)

        print(f"    Epoch {epoch}/{max_epochs}: loss={avg_loss:.4f}, "
              f"val_AUC-PR={val_auc:.4f} (best={best_val_auc:.4f})")

        if val_auc > best_val_auc:
            best_val_auc = val_auc
            best_state = {k: v.clone() for k, v in model.state_dict().items()}
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"    Early stopping (no improvement for {patience} epochs)")
                break

    # Decide whether to keep the new model
    keep_new = True
    if best_state is not None:
        model.load_state_dict(best_state)
    else:
        # No improvement at all
        keep_new = False

    # Final validation
    model.eval()
    post_metrics = evaluate_model(model, val_ds, device, temperature)
    post_auc = post_metrics.get("auc_pr", 0)
    pre_auc = pre_metrics.get("auc_pr", 0)

    # Safety check: revert if performance degraded
    if pre_auc > 0 and post_auc < pre_auc * MIN_AUC_PR_RATIO:
        print(f"\n  REVERTING: post AUC-PR ({post_auc:.4f}) < "
              f"{MIN_AUC_PR_RATIO:.0%} of pre ({pre_auc:.4f})")
        keep_new = False

    elapsed = (time.time() - start_time) / 60
    return {
        "pre_auc_pr": pre_auc,
        "post_auc_pr": post_auc,
        "best_val_auc_pr": best_val_auc,
        "epochs_trained": epoch,
        "keep_new_model": keep_new,
        "elapsed_minutes": round(elapsed, 1),
    }


def evaluate_model(
    model: PhysicsInformedTFT,
    dataset: CDMSequenceDataset,
    device: torch.device,
    temperature: float = 1.0,
) -> dict:
    """Quick evaluation on a dataset."""
    if len(dataset) == 0:
        return {"auc_pr": 0.0, "f1": 0.0}

    model.eval()
    loader = torch.utils.data.DataLoader(
        dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,
    )

    all_probs = []
    all_labels = []

    with torch.no_grad():
        for batch in loader:
            temporal = batch["temporal"].to(device)
            static = batch["static"].to(device)
            tca = batch["time_to_tca"].to(device)
            mask = batch["mask"].to(device)

            risk_logit, _, _ = model(temporal, static, tca, mask)
            probs = torch.sigmoid(risk_logit / temperature).cpu().numpy().flatten()
            labels = batch["risk_label"].numpy().flatten()

            all_probs.append(probs)
            all_labels.append(labels)

    y_prob = np.concatenate(all_probs)
    y_true = np.concatenate(all_labels)

    if y_true.sum() == 0:
        return {"auc_pr": 0.0, "f1": 0.0, "n_samples": len(y_true)}

    metrics = evaluate_risk(y_true, y_prob)
    metrics["n_samples"] = len(y_true)
    return metrics


def save_updated_model(model, checkpoint, finetune_results, device):
    """Save fine-tuned model with metadata."""
    # Backup old model
    old_path = MODEL_DIR / "transformer.pt"
    backup_path = MODEL_DIR / "transformer_backup.pt"
    if old_path.exists():
        import shutil
        shutil.copy2(old_path, backup_path)
        print(f"  Backed up old model to {backup_path}")

    # Update checkpoint
    checkpoint["model_state"] = model.state_dict()
    checkpoint["finetune_history"] = checkpoint.get("finetune_history", [])
    checkpoint["finetune_history"].append({
        "date": datetime.now(timezone.utc).isoformat(),
        **finetune_results,
    })
    checkpoint["epoch"] = checkpoint.get("epoch", 0)  # Keep original epoch

    torch.save(checkpoint, old_path)
    print(f"  Saved fine-tuned model to {old_path}")

    # Upload to HuggingFace
    hf_token = os.environ.get("HF_TOKEN", "")
    if hf_token:
        try:
            from huggingface_hub import HfApi
            api = HfApi(token=hf_token)
            repo_id = "DominicTanzillo/panacea-models"

            try:
                api.create_repo(repo_id, repo_type="model", exist_ok=True)
            except Exception:
                pass

            api.upload_file(
                path_or_fileobj=str(old_path),
                path_in_repo="transformer.pt",
                repo_id=repo_id,
                repo_type="model",
            )
            # Also upload backup
            api.upload_file(
                path_or_fileobj=str(backup_path),
                path_in_repo="transformer_backup.pt",
                repo_id=repo_id,
                repo_type="model",
            )
            print(f"  Uploaded to HuggingFace: {repo_id}")
        except Exception as e:
            print(f"  HuggingFace upload failed: {e}")


def main():
    parser = argparse.ArgumentParser(description="Weekly PI-TFT fine-tuning")
    parser.add_argument("--dry-run", action="store_true",
                        help="Check data availability, don't train")
    parser.add_argument("--local-only", action="store_true",
                        help="Use local outcome logs only")
    parser.add_argument("--max-epochs", type=int, default=MAX_EPOCHS)
    args = parser.parse_args()

    print(f"{'='*60}")
    print(f"  Panacea Weekly PI-TFT Fine-Tuning")
    print(f"  Date: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}")
    print(f"{'='*60}\n")

    device = torch.device("cpu")  # CPU-only for Actions runners
    print(f"Device: {device}")

    # 1. Load outcome data
    print("\nLoading outcome data ...")
    if args.local_only:
        outcomes = load_outcomes_from_local()
    else:
        outcomes = load_outcomes_from_firebase()
        if not outcomes:
            outcomes = load_outcomes_from_local()

    if not outcomes:
        print("\n  No outcome data available. Nothing to fine-tune.")
        return

    examples = outcomes_to_training_data(outcomes)

    if len(examples) < MIN_NEW_OUTCOMES:
        print(f"\n  Only {len(examples)} examples (need {MIN_NEW_OUTCOMES}). "
              f"Skipping fine-tuning — accumulate more data.")
        return

    if args.dry_run:
        print(f"\n  Dry run: {len(examples)} examples available for fine-tuning.")
        print(f"  Would train for up to {args.max_epochs} epochs.")
        return

    # 2. Load current model
    print("\nLoading model ...")
    model, checkpoint = load_model(device)
    if model is None:
        print("  Cannot load model. Aborting.")
        return

    # 3. Build training dataset from Kelvins + new outcomes
    #    We fine-tune on the ORIGINAL training data + new outcomes
    #    to avoid catastrophic forgetting
    print("\nBuilding datasets ...")
    from src.data.cdm_loader import load_dataset
    data_dir = ROOT / "data" / "cdm"

    try:
        train_df, test_df = load_dataset(data_dir)
    except FileNotFoundError:
        print("  Kelvins data not found on Actions runner — using outcomes only")
        train_df = None

    temporal_cols = checkpoint.get("temporal_cols", TEMPORAL_FEATURES)
    static_cols = checkpoint.get("static_cols", STATIC_FEATURES)

    if train_df is not None:
        # Pad missing columns
        for col in temporal_cols + static_cols:
            if col not in train_df.columns:
                train_df[col] = 0.0

        # Split training data for fine-tuning
        n_val = max(int(len(train_df["event_id"].unique()) * VAL_FRACTION), 10)
        event_ids = train_df["event_id"].unique()
        np.random.seed(42)
        np.random.shuffle(event_ids)
        val_ids = set(event_ids[:n_val])
        train_ids = set(event_ids[n_val:])

        ft_train_df = train_df[train_df["event_id"].isin(train_ids)]
        ft_val_df = train_df[train_df["event_id"].isin(val_ids)]

        train_ds = CDMSequenceDataset(
            ft_train_df, temporal_cols=temporal_cols, static_cols=static_cols,
        )
        val_ds = CDMSequenceDataset(
            ft_val_df, temporal_cols=temporal_cols, static_cols=static_cols,
        )
        val_ds.set_normalization(train_ds)

        print(f"  Train: {len(train_ds)} events, Val: {len(val_ds)} events")
        print(f"  New outcomes: {len(examples)} (will improve with more data)")
    else:
        print("  No base training data — skipping fine-tuning on Actions")
        print("  (Kelvins dataset too large for Actions runner)")
        return

    # 4. Fine-tune
    print(f"\nFine-tuning (max {args.max_epochs} epochs, LR={FINETUNE_LR}) ...")
    results = finetune_on_outcomes(
        model, checkpoint, train_ds, val_ds, device,
        max_epochs=args.max_epochs, lr=FINETUNE_LR,
    )

    print(f"\n  Results:")
    print(f"    Pre-finetune AUC-PR:  {results['pre_auc_pr']:.4f}")
    print(f"    Post-finetune AUC-PR: {results['post_auc_pr']:.4f}")
    print(f"    Epochs trained:       {results['epochs_trained']}")
    print(f"    Time elapsed:         {results['elapsed_minutes']:.1f} min")
    print(f"    Keep new model:       {results['keep_new_model']}")

    # 5. Save if improved
    if results["keep_new_model"]:
        print("\nSaving improved model ...")
        save_updated_model(model, checkpoint, results, device)
    else:
        print("\nKeeping original model (no improvement or degradation detected)")

    # 6. Log results
    log_path = LOG_DIR / "finetune_log.jsonl"
    log_path.parent.mkdir(parents=True, exist_ok=True)
    with open(log_path, "a") as f:
        results["date"] = datetime.now(timezone.utc).isoformat()
        results["n_outcomes"] = len(examples)
        f.write(json.dumps(results) + "\n")

    print(f"\n{'='*60}")
    print(f"  Fine-tuning complete!")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
