# Generated by Claude Code -- 2026-02-10
"""Self-supervised pre-training for the PI-TFT encoder.

Pre-trains the Transformer encoder on ALL CDM data (train + test, no labels)
using masked feature reconstruction. Saves encoder-only weights for downstream
fine-tuning.

Usage:
    python scripts/pretrain_deep.py                     # Default (50 epochs)
    python scripts/pretrain_deep.py --epochs 100        # Custom epochs
    python scripts/pretrain_deep.py --mask-ratio 0.5    # Custom mask ratio
"""

import sys
import time
import argparse
import numpy as np
import pandas as pd
import torch
from torch.utils.data import DataLoader
from pathlib import Path

ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from src.data.cdm_loader import load_dataset
from src.data.sequence_builder import PretrainDataset
from src.model.pretrain import PretrainingWrapper, PretrainingLoss


def get_device():
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"Using GPU: {torch.cuda.get_device_name()}")
        print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        device = torch.device("cpu")
        print("Using CPU (no CUDA GPU detected)")
    return device


def train_one_epoch(model, loader, criterion, optimizer, scaler, device):
    model.train()
    total_loss = 0
    n_batches = 0

    for batch in loader:
        temporal = batch["temporal"].to(device)
        static = batch["static"].to(device)
        tca = batch["time_to_tca"].to(device)
        mask = batch["mask"].to(device)

        optimizer.zero_grad()

        with torch.amp.autocast("cuda", enabled=scaler.is_enabled()):
            reconstructed, feature_mask, original = model(temporal, static, tca, mask)
            loss, metrics = criterion(reconstructed, original, feature_mask)

        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()

        total_loss += metrics["reconstruction_loss"]
        n_batches += 1

    return total_loss / max(n_batches, 1)


@torch.no_grad()
def evaluate_reconstruction(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    n_batches = 0

    for batch in loader:
        temporal = batch["temporal"].to(device)
        static = batch["static"].to(device)
        tca = batch["time_to_tca"].to(device)
        mask = batch["mask"].to(device)

        reconstructed, feature_mask, original = model(temporal, static, tca, mask)
        loss, metrics = criterion(reconstructed, original, feature_mask)

        total_loss += metrics["reconstruction_loss"]
        n_batches += 1

    return total_loss / max(n_batches, 1)


def main():
    parser = argparse.ArgumentParser(description="Pre-train PI-TFT encoder via masked reconstruction")
    parser.add_argument("--epochs", type=int, default=50)
    parser.add_argument("--batch-size", type=int, default=64)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--mask-ratio", type=float, default=0.6)
    parser.add_argument("--d-model", type=int, default=128)
    parser.add_argument("--n-heads", type=int, default=4)
    parser.add_argument("--n-layers", type=int, default=2)
    parser.add_argument("--patience", type=int, default=10)
    parser.add_argument("--val-fraction", type=float, default=0.1)
    parser.add_argument("--augmented", action="store_true",
                        help="Include augmented data in pre-training pool")
    args = parser.parse_args()

    device = get_device()
    data_dir = ROOT / "data" / "cdm"
    model_dir = ROOT / "models"
    model_dir.mkdir(parents=True, exist_ok=True)

    # Load ALL CDM data (train + test — no labels needed)
    print("Loading CDM dataset for pre-training ...")
    if args.augmented:
        from src.data.augment import build_augmented_training_set
        train_df, test_df = build_augmented_training_set(ROOT / "data")
    else:
        train_df, test_df = load_dataset(data_dir)

    # Combine train + test into a single pool
    combined_df = pd.concat([train_df, test_df], ignore_index=True)
    n_total_events = combined_df["event_id"].nunique()
    print(f"Combined: {len(combined_df)} rows, {n_total_events} events")

    # 90/10 random split by event_id for pre-train / val
    all_event_ids = combined_df["event_id"].unique()
    rng = np.random.RandomState(42)
    rng.shuffle(all_event_ids)
    n_val = max(1, int(len(all_event_ids) * args.val_fraction))
    val_ids = set(all_event_ids[:n_val])
    train_ids = set(all_event_ids[n_val:])

    pretrain_df = combined_df[combined_df["event_id"].isin(train_ids)]
    val_df = combined_df[combined_df["event_id"].isin(val_ids)]

    print(f"\nPre-train split: {len(train_ids)} train, {len(val_ids)} val events")

    # Build datasets
    print("\nBuilding pre-training datasets ...")
    pretrain_ds = PretrainDataset(pretrain_df)
    val_ds = PretrainDataset(val_df)
    val_ds.set_normalization(pretrain_ds)

    pretrain_loader = DataLoader(
        pretrain_ds, batch_size=args.batch_size, shuffle=True,
        num_workers=0, pin_memory=torch.cuda.is_available(),
    )
    val_loader = DataLoader(
        val_ds, batch_size=args.batch_size * 2, shuffle=False, num_workers=0,
    )

    # Model — temporal dim is doubled by delta features
    n_temporal = len(pretrain_ds.temporal_cols) * 2  # raw + deltas
    n_static = len(pretrain_ds.static_cols)

    model = PretrainingWrapper(
        n_temporal_features=n_temporal,
        n_static_features=n_static,
        d_model=args.d_model,
        n_heads=args.n_heads,
        n_layers=args.n_layers,
        dropout=0.15,
        mask_ratio=args.mask_ratio,
    ).to(device)

    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\nPretrainingWrapper: {n_params:,} parameters")
    print(f"  d_model={args.d_model}, n_heads={args.n_heads}, n_layers={args.n_layers}")
    print(f"  Mask ratio: {args.mask_ratio}")
    print(f"  Temporal features: {n_temporal}, Static features: {n_static}")

    criterion = PretrainingLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-2)

    # Cosine annealing schedule
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.epochs, eta_min=1e-6
    )

    # Mixed precision
    use_amp = device.type == "cuda"
    scaler = torch.amp.GradScaler("cuda", enabled=use_amp)

    # Training loop
    print(f"\n{'='*60}")
    print(f"  Pre-training for {args.epochs} epochs (patience={args.patience})")
    print(f"  Batch size: {args.batch_size}, LR: {args.lr}")
    print(f"  Mixed precision: {use_amp}")
    print(f"{'='*60}\n")

    best_val_loss = float("inf")
    patience_counter = 0
    start_time = time.time()

    for epoch in range(1, args.epochs + 1):
        epoch_start = time.time()

        train_loss = train_one_epoch(model, pretrain_loader, criterion, optimizer, scaler, device)
        val_loss = evaluate_reconstruction(model, val_loader, criterion, device)

        scheduler.step()

        elapsed = time.time() - epoch_start
        total_elapsed = time.time() - start_time
        current_lr = optimizer.param_groups[0]["lr"]

        print(f"Epoch {epoch:3d}/{args.epochs} | "
              f"train_recon={train_loss:.6f} | "
              f"val_recon={val_loss:.6f} | "
              f"lr={current_lr:.2e} | "
              f"{elapsed:.1f}s | total={total_elapsed/60:.1f}min")

        # Early stopping on val reconstruction loss
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0

            # Save encoder-only weights (strip reconstruction head, masking)
            encoder_state = model.encoder.state_dict()
            torch.save({
                "encoder_state": encoder_state,
                "epoch": epoch,
                "val_reconstruction_loss": best_val_loss,
                "config": {
                    "n_temporal": n_temporal,
                    "n_static": n_static,
                    "d_model": args.d_model,
                    "n_heads": args.n_heads,
                    "n_layers": args.n_layers,
                    "mask_ratio": args.mask_ratio,
                },
                "normalization": {
                    "temporal_mean": pretrain_ds.temporal_mean.tolist(),
                    "temporal_std": pretrain_ds.temporal_std.tolist(),
                    "delta_mean": pretrain_ds.delta_mean.tolist(),
                    "delta_std": pretrain_ds.delta_std.tolist(),
                    "static_mean": pretrain_ds.static_mean.tolist(),
                    "static_std": pretrain_ds.static_std.tolist(),
                    "tca_mean": pretrain_ds.tca_mean,
                    "tca_std": pretrain_ds.tca_std,
                },
                "temporal_cols": pretrain_ds.temporal_cols,
                "static_cols": pretrain_ds.static_cols,
            }, model_dir / "pretrained_encoder.pt")
            print(f"  ** New best val recon loss: {best_val_loss:.6f} — saved encoder **")
        else:
            patience_counter += 1
            if patience_counter >= args.patience:
                print(f"\nEarly stopping at epoch {epoch} (patience={args.patience})")
                break

    total_time = time.time() - start_time
    print(f"\n{'='*60}")
    print(f"  Pre-training complete!")
    print(f"  Best val reconstruction loss: {best_val_loss:.6f}")
    print(f"  Total time: {total_time/60:.1f} minutes")
    print(f"  Saved: models/pretrained_encoder.pt")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
