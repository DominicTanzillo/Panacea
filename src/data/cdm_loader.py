# Generated by Claude Code -- 2026-02-08
"""Load and parse ESA Kelvins CDM dataset into structured formats."""

import pandas as pd
import numpy as np
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Optional


@dataclass
class CDMSnapshot:
    """A single Conjunction Data Message update."""
    time_to_tca: float
    miss_distance: float
    relative_speed: float
    risk: float
    features: np.ndarray  # all numeric columns as a flat vector


@dataclass
class ConjunctionEvent:
    """A complete conjunction event = sequence of CDM snapshots."""
    event_id: int
    cdm_sequence: List[CDMSnapshot] = field(default_factory=list)
    risk_label: int = 0  # 1 if any CDM in sequence has high risk
    final_miss_distance: float = 0.0
    altitude_km: float = 0.0
    object_type: str = ""


# Columns we use for the feature vector (numeric only, excluding IDs/targets)
EXCLUDE_COLS = {"event_id", "time_to_tca", "risk", "mission_id"}


def load_cdm_csv(path: Path) -> pd.DataFrame:
    """Load a CDM CSV and do basic cleaning."""
    df = pd.read_csv(path)

    # Identify numeric columns for features
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in numeric_cols if c not in EXCLUDE_COLS]

    # Fill NaN with 0 for numeric features (some covariance cols are sparse)
    df[feature_cols] = df[feature_cols].fillna(0)

    return df


def load_dataset(data_dir: Path) -> tuple[pd.DataFrame, pd.DataFrame]:
    """Load train and test CDM DataFrames."""
    # Find the CSV files (may be in subdirectory after extraction)
    train_candidates = list(data_dir.rglob("*train*.csv"))
    test_candidates = list(data_dir.rglob("*test*.csv"))

    if not train_candidates:
        raise FileNotFoundError(f"No train CSV found in {data_dir}")
    if not test_candidates:
        raise FileNotFoundError(f"No test CSV found in {data_dir}")

    train_path = train_candidates[0]
    test_path = test_candidates[0]

    print(f"Loading train: {train_path}")
    print(f"Loading test:  {test_path}")

    train_df = load_cdm_csv(train_path)
    test_df = load_cdm_csv(test_path)

    print(f"Train: {len(train_df)} rows, {train_df['event_id'].nunique()} events")
    print(f"Test:  {len(test_df)} rows, {test_df['event_id'].nunique()} events")

    return train_df, test_df


def get_feature_columns(df: pd.DataFrame) -> list[str]:
    """Get the list of numeric feature columns (excluding IDs and targets)."""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    return [c for c in numeric_cols if c not in EXCLUDE_COLS]


def build_events(df: pd.DataFrame) -> list[ConjunctionEvent]:
    """Group CDM rows by event_id into ConjunctionEvent objects."""
    feature_cols = get_feature_columns(df)
    events = []

    for event_id, group in df.groupby("event_id"):
        # Sort by time_to_tca descending (earliest CDM first, closest to TCA last)
        group = group.sort_values("time_to_tca", ascending=False)

        cdm_seq = []
        for _, row in group.iterrows():
            snap = CDMSnapshot(
                time_to_tca=row["time_to_tca"],
                miss_distance=row.get("miss_distance", 0.0),
                relative_speed=row.get("relative_speed", 0.0),
                risk=row.get("risk", 0.0),
                features=row[feature_cols].values.astype(np.float32),
            )
            cdm_seq.append(snap)

        # Final CDM (closest to TCA) has the best estimate
        final_cdm = cdm_seq[-1]

        # Risk label: use the risk column from the final CDM
        # In the Kelvins dataset, risk is log10(collision_probability)
        # High risk = risk > -5 (i.e., collision prob > 1e-5)
        risk_label = 1 if final_cdm.risk > -5 else 0

        # Approximate altitude from semi-major axis columns if available
        alt = 0.0
        for col_prefix in ["t_h_apo", "c_h_apo"]:
            if col_prefix in df.columns:
                alt = group[col_prefix].iloc[-1]
                break

        event = ConjunctionEvent(
            event_id=int(event_id),
            cdm_sequence=cdm_seq,
            risk_label=risk_label,
            final_miss_distance=final_cdm.miss_distance,
            altitude_km=alt,
            object_type=str(group.get("c_object_type", pd.Series(["unknown"])).iloc[0]),
        )
        events.append(event)

    print(f"Built {len(events)} events, "
          f"{sum(e.risk_label for e in events)} high-risk "
          f"({100*sum(e.risk_label for e in events)/len(events):.1f}%)")

    return events


def events_to_flat_features(events: list[ConjunctionEvent]) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Extract flat feature vectors from events for classical ML.
    Uses the LAST CDM snapshot (closest to TCA) + temporal trend features.

    Returns: (X, y_risk, y_miss)
    """
    X_list = []
    y_risk = []
    y_miss = []

    for event in events:
        seq = event.cdm_sequence
        last = seq[-1]

        # Base features from latest CDM
        base = last.features.copy()

        # Temporal trend features (computed over the CDM sequence)
        miss_values = np.array([s.miss_distance for s in seq])
        risk_values = np.array([s.risk for s in seq])
        tca_values = np.array([s.time_to_tca for s in seq])

        # Trends and statistics
        n_cdms = len(seq)
        miss_mean = np.mean(miss_values) if n_cdms > 0 else 0
        miss_std = np.std(miss_values) if n_cdms > 1 else 0
        miss_trend = 0.0
        if n_cdms > 1 and np.std(tca_values) > 0:
            # Linear regression slope of miss_distance vs time_to_tca
            miss_trend = np.polyfit(tca_values, miss_values, 1)[0]

        risk_trend = 0.0
        if n_cdms > 1 and np.std(tca_values) > 0:
            risk_trend = np.polyfit(tca_values, risk_values, 1)[0]

        temporal_feats = np.array([
            n_cdms,
            miss_mean,
            miss_std,
            miss_trend,
            risk_trend,
            miss_values[0] - miss_values[-1] if n_cdms > 1 else 0,  # total miss change
            last.time_to_tca,
            last.relative_speed,
        ], dtype=np.float32)

        combined = np.concatenate([base, temporal_feats])
        X_list.append(combined)
        y_risk.append(event.risk_label)
        y_miss.append(np.log1p(event.final_miss_distance))

    X = np.stack(X_list)
    # Replace any remaining NaN/inf
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

    return X, np.array(y_risk), np.array(y_miss)
