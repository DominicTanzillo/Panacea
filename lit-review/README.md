<!-- Generated by Claude Code — 2026-02-09 -->

# Panacea Literature Review

**Project**: Panacea — Satellite Collision Avoidance using Machine Learning
**Course**: AIPI 540 — Deep Learning Applications (Duke University)
**Developer**: Dominic Tanzillo

---

## Purpose

This literature review supports the AIPI 540 final project by surveying the research landscape around machine learning for spacecraft conjunction assessment. The project uses the ESA Kelvins Conjunction Data Messages (CDM) dataset to train three models — a naive baseline (logistic regression), a classical ML model (XGBoost), and a deep learning model (Physics-Informed Temporal Fusion Transformer) — and this review contextualizes their design choices and expected performance.

## Table of Contents

| # | File | Topic |
|---|------|-------|
| 1 | [01-kelvins-challenge.md](./01-kelvins-challenge.md) | ESA Kelvins Collision Avoidance Challenge — competition results and winning solutions |
| 2 | [02-cdm-ml-approaches.md](./02-cdm-ml-approaches.md) | ML approaches for conjunction assessment beyond the competition |
| 3 | [03-temporal-vs-flat.md](./03-temporal-vs-flat.md) | Do we need time series modeling for CDMs? Arguments for and against sequence models |
| 4 | [04-tabular-dl.md](./04-tabular-dl.md) | Trees vs. deep learning on tabular data — the broader research consensus |
| 5 | [05-training-techniques.md](./05-training-techniques.md) | Training techniques relevant to improving the PI-TFT |
| 6 | [06-implications.md](./06-implications.md) | Synthesis — what does this all mean for Panacea? |

## Key Findings

1. **Gradient boosting dominates CDM-based collision prediction.** The ESA Kelvins competition (73 teams) was won decisively by XGBoost/LightGBM ensembles with heavy temporal feature engineering. No neural network approach placed in the top tier.

2. **This is consistent with the broader tabular data literature.** Multiple large-scale benchmarks (Grinsztajn et al. 2022, McElfresh et al. 2023) confirm that tree-based models outperform deep learning on structured datasets with fewer than ~50K samples. The Kelvins CDM dataset has ~13K events — firmly in tree-favored territory.

3. **Temporal modeling is theoretically justified but practically unnecessary.** CDMs evolve as time-to-closest-approach decreases, and sequential patterns carry meaning. However, manual feature engineering (deltas, rates of change, moving averages) captures these dynamics effectively, and competition evidence shows flat models with engineered features outperform sequence models on this dataset.

4. **Panacea's XGBoost AUC-PR of 0.978 is consistent with state-of-the-art.** The PI-TFT's current AUC-PR of 0.50 reflects the known difficulty of training transformers on small tabular datasets, not an implementation error.

5. **The performance gap itself is a meaningful result.** For the AIPI 540 presentation, the three-model comparison tells a pedagogically valuable story about when deep learning does and does not outperform classical methods.

## Citation Style

Papers are cited in-text as Author et al. (Year) with full titles provided on first reference. All citations include enough detail to locate the original work.
