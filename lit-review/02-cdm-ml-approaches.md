<!-- Generated by Claude Code — 2026-02-09 -->

# ML Approaches for Conjunction Assessment

## Overview

Beyond the ESA Kelvins competition, there is a growing body of work applying machine learning and statistical methods to spacecraft conjunction assessment. This review covers operational systems, Bayesian approaches, sequential models, and agency-specific tooling.

---

## Operational Systems

### NASA Conjunction Assessment Risk Analysis (CARA)

NASA's CARA program at the Goddard Space Flight Center is the primary operational conjunction assessment system for US-operated spacecraft.

- **Process**: The 18th Space Defense Squadron (formerly JSpOC) screens all tracked objects and issues CDMs when predicted close approaches fall below distance thresholds. CARA receives these CDMs and performs detailed risk analysis for NASA missions.
- **Current approach**: Primarily physics-based — Monte Carlo orbit propagation with covariance realism analysis. The probability of collision (Pc) is computed by integrating the combined position uncertainty over the collision cross-section (hard-body radius).
- **ML integration**: CARA has explored ML for **CDM screening** (quickly triaging which CDMs warrant human attention) and **covariance realism assessment** (detecting when reported uncertainties are under- or over-estimated). These are complementary to, not replacements for, the physics-based Pc calculation.
- **Key challenge**: The false positive rate is extremely high. Of the thousands of CDMs processed per year, very few represent genuine collision risk. This extreme class imbalance (addressed in Panacea via balanced sampling and focal loss) is the central ML challenge.

**Relevance to Panacea**: Our problem formulation (binary classification: high-risk vs. low-risk) mirrors CARA's screening task. The class imbalance we observe in the Kelvins dataset reflects real operational conditions.

### ESA Kessler Library

- ESA's internal conjunction assessment toolkit for operational risk management.
- Implements standard Pc computation methods (Alfano, Chan, Foster) alongside ML-augmented screening.
- Used as the baseline system against which Kelvins competition solutions were compared.

---

## Bayesian and Probabilistic Approaches

### Bayesian CDM Uncertainty Quantification

Several research groups have applied Bayesian methods to CDM analysis:

- **Gaussian Process regression** for modeling the evolution of miss distance and Pc over the CDM sequence. GPs naturally provide uncertainty estimates, which is critical for risk-averse decision making in conjunction assessment.
- **Bayesian Neural Networks (BNNs)** have been explored for Pc prediction with calibrated uncertainty. The advantage over point-estimate models (like standard XGBoost) is that BNNs can express *how confident* the model is in its prediction — operationally valuable for "how much should we trust this risk estimate?"
- **Ensemble methods for uncertainty**: Rather than a single model, using an ensemble of XGBoost models trained on bootstrap samples to produce prediction intervals. This approaches Bayesian uncertainty without the computational cost of full Bayesian inference.

**Relevance to Panacea**: Our current models produce point estimates. Future work could add uncertainty quantification via XGBoost ensembles or MC-dropout in the PI-TFT. Temperature scaling (covered in training techniques) is a lightweight step in this direction.

### Poisson Process Models

- Collision events can be modeled as a **non-homogeneous Poisson process** where the rate parameter varies with orbital characteristics and space debris density.
- This population-level approach complements the event-level CDM analysis: Poisson models estimate the *background rate* of close approaches, while CDM ML models assess the *severity* of individual encounters.
- Research by Alfano and others has shown that combining population-level priors with event-level CDM features can improve calibration of risk estimates.

---

## Sequential and Time Series Methods

### Hidden Markov Models (HMMs) for CDM Sequence Evolution

- CDMs for a single event arrive at irregular intervals over days to weeks before TCA. The evolution of key parameters (miss distance, Pc, covariance size) follows recognizable patterns.
- **HMM formulations** model the CDM sequence as transitions between latent states: "converging" (miss distance decreasing steadily), "stable" (parameters settled), "jump" (sudden orbit determination update changes values dramatically), "settled-high-risk" vs. "settled-low-risk."
- HMMs can detect state transitions (e.g., "the miss distance just jumped — was this an OD update?") which may be informative for risk assessment.
- In practice, the added complexity of HMMs has not clearly outperformed simpler feature engineering approaches (e.g., computing delta-miss-distance and flagging large jumps directly).

**Relevance to Panacea**: The PI-TFT's temporal attention mechanism is conceptually related to HMM state detection — it can learn to attend to "jump" events in the CDM sequence. However, the same information can be captured by engineered delta features fed to XGBoost.

### Recurrent Neural Networks

- LSTMs and GRUs have been applied to CDM sequences, treating each event's CDM series as a variable-length time series.
- These models can naturally handle the irregular temporal spacing and variable sequence lengths of CDM data.
- Results have been mixed: RNNs can capture temporal dynamics but tend to underperform tree-based models with engineered features on the Kelvins dataset. The primary limitation is dataset size — 13K events is insufficient for RNNs to learn temporal representations that beat hand-crafted ones.

---

## Agency-Specific Approaches

### CNES (French Space Agency) — Automated Conjunction Screening

- CNES has developed automated screening pipelines that combine rule-based filters with ML classifiers.
- Their approach uses a **cascade of increasingly expensive analyses**: simple distance thresholds -> ML pre-screening -> detailed Monte Carlo analysis only for flagged events.
- This cascade design is operationally motivated: it reduces the computational burden of full Monte Carlo analysis by filtering out obviously safe events early.
- ML is used at the screening stage, where XGBoost classifiers trained on historical CDMs learn to predict which events will eventually be flagged as high-risk.

**Relevance to Panacea**: Our binary classification formulation aligns with the screening task in CNES's cascade. The emphasis on high recall (don't miss genuine risks) motivates our focus on AUC-PR and F1 rather than raw accuracy.

### JAXA and International Collaboration

- International Space Station (ISS) conjunction assessment involves coordination between NASA, ESA, JAXA, and other partners.
- Each agency may receive different CDMs for the same event (based on their own orbit determination solutions), creating an interesting multi-source data fusion problem.
- Research on **sensor fusion** approaches — combining CDMs from multiple sources — is an active area, though data sharing limitations make this difficult to study publicly.

---

## Summary of Approaches

| Approach | Strengths | Limitations | Performance vs. XGBoost |
|----------|-----------|-------------|------------------------|
| XGBoost + feature engineering | Fast, interpretable, strong performance | No native uncertainty, manual features | **Baseline (best)** |
| Bayesian methods (GP, BNN) | Calibrated uncertainty | Computational cost, complex implementation | Comparable, with better calibration |
| HMMs | Principled sequential modeling | Hidden state selection, limited by small data | Slightly worse on Kelvins |
| RNNs (LSTM/GRU) | End-to-end temporal learning | Need more data, harder to train | Worse on Kelvins |
| Transformers | Attention over full sequence | Data-hungry, overfitting risk | Worse on small datasets |
| Rule-based + ML cascade | Operationally practical | Requires domain expertise for rules | ML stage comparable |
