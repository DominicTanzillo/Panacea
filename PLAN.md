<!-- Generated by Claude Code (Claude Opus 4.6) — 2026-02-07 -->

# Panacea — Orbital Debris Collision Prediction & Visualization Platform

## Table of Contents
1. [Project Overview](#1-project-overview)
2. [Data Sources & Ingestion](#2-data-sources--ingestion)
3. [Data Schema & Feature Engineering](#3-data-schema--feature-engineering)
4. [Modeling Approaches](#4-modeling-approaches)
5. [Experiment: TLE Staleness Sensitivity Analysis](#5-experiment-tle-staleness-sensitivity-analysis)
6. [Application Architecture](#6-application-architecture)
7. [Frontend: 3D Orbital Visualization](#7-frontend-3d-orbital-visualization)
8. [Backend: FastAPI Inference Server](#8-backend-fastapi-inference-server)
9. [Deployment & Hosting](#9-deployment--hosting)
10. [Repository Structure](#10-repository-structure)
11. [Development Phases](#11-development-phases)
12. [Evaluation & Metrics](#12-evaluation--metrics)
13. [Risk Analysis & Mitigations](#13-risk-analysis--mitigations)

---

## 1. Project Overview

### Mission Statement
Panacea is an AI-powered space situational awareness platform that predicts orbital conjunction events (potential collisions) between tracked objects in Earth orbit, visualizes the full debris environment in an interactive 3D globe, and provides risk-scored alerts with actionable recommendations.

### Why This Matters
- ~30,000 tracked objects orbit Earth; millions of untracked fragments exist
- Kessler Syndrome — cascading collisions that render orbital shells unusable — is a real and growing threat
- SpaceX Starlink performs thousands of collision avoidance maneuvers per year
- ESA, NASA, and the US Space Force are actively seeking ML-augmented conjunction assessment
- The commercial space situational awareness (SSA) market exceeds $1B and is growing >15% CAGR

### Course Requirements Mapping
| Requirement | Implementation |
|---|---|
| Naive baseline | Orbital shell density prior (altitude-band collision rate) |
| Classical ML model | XGBoost on engineered CDM features (103 features → miss distance regression) |
| Deep learning model | Temporal Transformer on CDM time series (sequence of updates → final risk) |
| Focused experiment | TLE staleness sensitivity analysis: prediction accuracy vs. data age |
| Interactive application | 3D Earth + real-time orbits + conjunction alerts + risk dashboard |
| Publicly accessible | GitHub Pages (frontend) + GitHub Actions + Cloudflare tunnel (API) |
| Live 1+ week | Dual ping-pong inference servers for continuous uptime |
| Inference only in app | All training offline; app loads pretrained weights from HuggingFace Hub |

### Key Differentiators
- **Real-time 3D visualization** of the entire tracked debris catalog — not just charts
- **Temporal deep learning** on conjunction data message sequences (not single-snapshot classification)
- **Operationally relevant experiment**: TLE staleness directly impacts mission planning decisions
- **Full SkinTag-grade deployment infrastructure**: ping-pong servers, git notes API routing, zero cost

---

## 2. Data Sources & Ingestion

### 2.1 ESA Kelvins Conjunction Data Messages (Primary Training Data)

**Source**: ESA Space Debris Office via Zenodo
**URL**: https://zenodo.org/records/4463683
**License**: Open, free download
**Period**: 2015–2019 real operational data (anonymized)

| Split | CDM Rows | Unique Events | Avg CDMs/Event |
|---|---|---|---|
| Train | 162,634 | 13,154 | ~12 |
| Test | 24,484 | 2,167 | ~11 |
| **Total** | **187,118** | **15,321** | ~12 |

**Schema**: 103 columns per CDM row including:

**Temporal features**:
- `time_to_tca`: Time remaining until closest approach (days). Decreases across CDMs within an event.
- `event_id`: Groups CDMs belonging to the same conjunction event.

**Orbital state features** (for both objects):
- Semi-major axis, eccentricity, inclination, RAAN, argument of perigee, mean anomaly
- Apoapsis/periapsis altitudes
- Object type (payload, rocket body, debris, unknown)

**Conjunction geometry**:
- `miss_distance`: Euclidean distance at time of closest approach (km) — **primary target**
- `relative_speed`: Relative velocity between objects (km/s)
- Radial, in-track, cross-track miss distance components (R, T, N)
- Mahalanobis distance

**Covariance / Uncertainty**:
- Full 6×6 covariance matrices for both objects (position + velocity uncertainty)
- Combined covariance eigenvalues
- Collision probability (computed via various methods)

**Target Variable**: `risk` — binary label indicating whether the event was classified as high-risk (requiring action) by ESA operators. Also regression targets: `miss_distance`, `mahalanobis_distance`.

### 2.2 CelesTrak Live Orbital Data (Visualization + Inference)

**URL**: `https://celestrak.org/NORAD/elements/gp.php?GROUP=<group>&FORMAT=json`
**Registration**: None required
**Update frequency**: Every 2 hours

**Available groups** (relevant):
| Group | Description | Approx Count |
|---|---|---|
| `active` | All active satellites | ~9,000 |
| `cosmos-2251-debris` | 2009 collision debris | ~250 |
| `iridium-33-debris` | 2009 collision debris | ~100 |
| `fengyun-1c-debris` | 2007 ASAT test debris | ~3,000 |
| `cosmos-1408-debris` | 2021 ASAT test debris | ~400 |
| `stations` | ISS, Tiangong, etc. | ~15 |
| `starlink` | SpaceX Starlink constellation | ~6,000 |
| `oneweb` | OneWeb constellation | ~600 |
| `visual` | Bright/visible objects | ~200 |

**Per-object JSON fields** (17 parameters):
```
OBJECT_NAME, OBJECT_ID, EPOCH, MEAN_MOTION, ECCENTRICITY,
INCLINATION, RA_OF_ASC_NODE, ARG_OF_PERICENTER, MEAN_ANOMALY,
EPHEMERIS_TYPE, CLASSIFICATION_TYPE, NORAD_CAT_ID, ELEMENT_SET_NO,
REV_AT_EPOCH, BSTAR, MEAN_MOTION_DOT, MEAN_MOTION_DDOT
```

**Ingestion strategy**:
- Frontend fetches TLEs on page load (or from a cached daily snapshot)
- `satellite.js` propagates all objects to current time client-side (SGP4)
- No backend needed for basic visualization — pure client-side orbital mechanics
- Backend only called for ML inference (conjunction prediction)

### 2.3 UCS Satellite Database (Enrichment / Metadata)

**URL**: https://www.ucsusa.org/resources/satellite-database
**Format**: Excel (.xlsx), also on Kaggle
**Fields**: Satellite name, country, operator, purpose (civil/military/commercial), orbit class (LEO/MEO/GEO), launch date, mass, expected lifetime, contractor
**Use**: Enrich the visualization with satellite purpose, operator, country. Power filtering (e.g., show only military satellites, show only Starlink).

### 2.4 Data Pipeline

```
[ESA Kelvins CDMs]                    [CelesTrak TLEs]         [UCS Database]
   (Zenodo CSV)                        (Live JSON API)          (Excel/Kaggle)
       |                                    |                        |
       v                                    v                        v
  scripts/download_cdm.py          scripts/fetch_tles.py     scripts/fetch_ucs.py
       |                                    |                        |
       v                                    v                        v
  data/cdm/train.csv               data/tle/active.json       data/ucs/satellites.csv
  data/cdm/test.csv                data/tle/debris_*.json
       |                                    |
       v                                    v
  src/data/cdm_loader.py          webapp-react/ (client-side)
  src/data/feature_eng.py          satellite.js propagation
       |
       v
  Training / Evaluation Pipeline
```

---

## 3. Data Schema & Feature Engineering

### 3.1 Unified CDM Sample Schema

```python
@dataclass
class ConjunctionEvent:
    event_id: str
    cdm_sequence: List[CDMSnapshot]     # Time-ordered CDM updates
    final_miss_distance: float          # km, ground truth
    final_collision_prob: float         # operator-computed
    risk_label: int                     # 0 = safe, 1 = high-risk
    object_1_type: str                  # payload, rocket_body, debris, unknown
    object_2_type: str
    max_relative_speed: float           # km/s

@dataclass
class CDMSnapshot:
    time_to_tca: float                  # Days until closest approach
    miss_distance: float                # Current estimate (km)
    miss_distance_r: float              # Radial component
    miss_distance_t: float              # In-track component
    miss_distance_n: float              # Cross-track component
    relative_speed: float               # km/s
    mahalanobis_distance: float
    collision_probability: float
    # Object 1 orbital elements
    o1_semi_major_axis: float
    o1_eccentricity: float
    o1_inclination: float
    o1_raan: float
    o1_arg_perigee: float
    o1_perigee_alt: float
    o1_apogee_alt: float
    # Object 2 orbital elements (same fields)
    ...
    # Covariance features
    cov_eigenvalue_1: float
    cov_eigenvalue_2: float
    cov_eigenvalue_3: float
    uncertainty_volume: float           # det(covariance)^(1/2)
```

### 3.2 Engineered Features (for Classical ML)

**Relative orbital geometry** (computed from object pairs):
| Feature | Description |
|---|---|
| `delta_inclination` | Absolute difference in orbital inclination (°) |
| `delta_raan` | RAAN difference, wrapped to [0, 180] (°) |
| `perigee_apogee_overlap` | Whether altitude bands overlap (binary + continuous) |
| `altitude_band` | Mean altitude of closest approach (km) |
| `relative_velocity` | Relative speed at TCA (km/s) |
| `approach_angle` | Angle between velocity vectors at TCA (°) |
| `coplanar_score` | How nearly coplanar the two orbits are |

**Temporal features** (from CDM sequence):
| Feature | Description |
|---|---|
| `miss_distance_trend` | Slope of miss_distance over last N CDMs |
| `miss_distance_volatility` | Std dev of miss_distance across CDM sequence |
| `miss_distance_latest` | Most recent CDM miss distance estimate |
| `time_to_tca` | How far out we're predicting (days) |
| `n_cdms_received` | Number of CDM updates received so far |
| `covariance_shrink_rate` | Rate at which uncertainty is decreasing |
| `collision_prob_trend` | Slope of collision probability estimates |
| `mahalanobis_trend` | Slope of Mahalanobis distance |

**Object metadata** (from UCS enrichment):
| Feature | Description |
|---|---|
| `object_1_type` | Payload / rocket body / debris / unknown (one-hot) |
| `object_2_type` | Same |
| `object_1_maneuverability` | Can it dodge? (active sat = yes, debris = no) |
| `altitude_regime` | LEO / MEO / HEO / GEO |
| `congestion_index` | Number of objects within ±50km altitude band |

### 3.3 Sequence Representation (for Deep Learning)

Each conjunction event is a **variable-length time series** of CDM snapshots, ordered by decreasing `time_to_tca`. The deep learning model sees:

```
Input: [CDM_t-12, CDM_t-11, ..., CDM_t-2, CDM_t-1]  →  Predict: final_miss_distance, risk_label
```

Each CDM snapshot is a feature vector of ~40 selected columns (from the 103 available). The sequence length averages ~12 but varies from 2 to 50+.

Padding/truncation strategy:
- Max sequence length: 30 (covers 95th percentile)
- Shorter sequences: left-pad with zeros + attention mask
- Longer sequences: keep most recent 30 CDMs (closest to TCA = most informative)

---

## 4. Modeling Approaches

### 4.1 Model 1: Naive Baseline — Orbital Shell Density Prior

**Location**: `src/model/baseline.py`

**Logic**: Predict collision risk based solely on the altitude band of the conjunction, using historical base rates.

```python
class OrbitalShellBaseline:
    """
    For any conjunction event, predict the average risk
    and average miss distance for that altitude regime.
    """
    def fit(self, events: List[ConjunctionEvent]):
        # Bin events by altitude (50km bands from 200-2000km)
        # Compute per-bin: mean miss_distance, mean collision_prob, risk rate
        self.altitude_bins = {}
        for event in events:
            band = round(event.altitude / 50) * 50
            self.altitude_bins[band].append(event)
        # Compute statistics per band

    def predict(self, altitude_km: float) -> dict:
        band = round(altitude_km / 50) * 50
        return {
            "predicted_miss_distance": self.altitude_bins[band].mean_miss,
            "predicted_risk": self.altitude_bins[band].risk_rate,
            "predicted_collision_prob": self.altitude_bins[band].mean_prob,
        }
```

**Purpose**: Establishes that altitude alone is predictive (LEO is more crowded) but insufficient. Demonstrates why we need object-pair-specific features.

**Expected performance**: Poor. Most conjunctions at any altitude are safe, so this will predict low risk for everything → high accuracy but terrible recall on actual high-risk events. F1 on risk class likely <0.10.

### 4.2 Model 2: Classical ML — XGBoost on Engineered Features

**Location**: `src/model/classical.py`

**Logic**: For each conjunction event, extract the **latest CDM snapshot** plus temporal trend features computed over the CDM sequence → feed a single feature vector to XGBoost.

```python
class XGBoostConjunctionModel:
    def __init__(self):
        self.feature_engineer = CDMFeatureEngineer()
        self.risk_classifier = XGBClassifier(
            n_estimators=500,
            max_depth=8,
            learning_rate=0.05,
            scale_pos_weight=50,   # Severe class imbalance (few high-risk events)
            eval_metric="aucpr",
            use_label_encoder=False,
        )
        self.miss_regressor = XGBRegressor(
            n_estimators=500,
            max_depth=8,
            learning_rate=0.05,
            objective="reg:squaredlogerror",  # Log-scale miss distance
        )

    def fit(self, events: List[ConjunctionEvent]):
        X = self.feature_engineer.transform(events)  # (N, ~60 features)
        y_risk = [e.risk_label for e in events]
        y_miss = [np.log1p(e.final_miss_distance) for e in events]
        self.risk_classifier.fit(X, y_risk)
        self.miss_regressor.fit(X, y_miss)

    def predict(self, event_cdms: List[CDMSnapshot]) -> dict:
        X = self.feature_engineer.transform_single(event_cdms)
        risk_prob = self.risk_classifier.predict_proba(X)[0, 1]
        log_miss = self.miss_regressor.predict(X)[0]
        return {
            "risk_probability": risk_prob,
            "predicted_miss_distance_km": np.expm1(log_miss),
        }
```

**Key design decisions**:
- `scale_pos_weight=50`: High-risk events are ~2% of dataset. Must aggressively upweight.
- `reg:squaredlogerror`: Miss distances span 5+ orders of magnitude (0.01 km to 10,000+ km). Log-scale regression handles this.
- Dual heads: One classifier (risk/safe), one regressor (miss distance). The classifier is the primary output; the regressor gives interpretable distance.

**Expected performance**: Strong. XGBoost excels on tabular features. ESA Kelvins challenge winners used gradient boosting. Expected AUC-PR ~0.5-0.7 on risk classification (this is a very hard, imbalanced problem).

### 4.3 Model 3: Deep Learning -- Physics-Informed Temporal Fusion Transformer (PI-TFT)

**Location**: `src/model/deep.py`

**Hardware**: RTX 4070 Ti SUPER (16GB VRAM) local, $50 GCP credits for sweeps

**Architecture**: This is the ambitious, publishable model. It combines three ideas that have not been combined before in the conjunction assessment literature:

1. **Temporal Fusion Transformer (TFT)** -- Google's architecture for multi-horizon structured time series. Unlike a vanilla Transformer, TFT has built-in variable selection networks that automatically learn which CDM features matter, gated residual connections for skip paths, and separate encoders for static metadata vs. time-varying CDM observations.

2. **Physics-Informed Loss** -- A regularization term that penalizes predictions violating Keplerian orbital mechanics. If the model predicts a miss distance that is physically impossible given the objects' orbital elements and propagation time, it incurs a penalty. This constrains the hypothesis space to physically plausible trajectories.

3. **Multi-Task Learning** -- Three prediction heads (risk classification, miss distance regression, time-to-closest-approach regression) share the Transformer backbone. Joint training forces the shared representation to learn richer orbital dynamics.

```python
class PhysicsInformedTFT(nn.Module):
    """
    Physics-Informed Temporal Fusion Transformer for conjunction assessment.

    Static inputs:  object types, altitude regime, maneuverability (processed once)
    Temporal inputs: CDM sequence (variable-length, irregularly spaced)
    Outputs:         risk probability, miss distance (km), TCA estimate
    """
    def __init__(
        self,
        n_temporal_features: int = 40,
        n_static_features: int = 12,
        d_model: int = 256,
        n_heads: int = 8,
        n_layers: int = 4,
        d_ff: int = 512,
        dropout: float = 0.15,
        max_seq_len: int = 30,
    ):
        super().__init__()

        # --- Variable Selection Networks (learn which features matter) ---
        self.static_vsn = VariableSelectionNetwork(
            n_features=n_static_features, d_model=d_model, dropout=dropout
        )
        self.temporal_vsn = VariableSelectionNetwork(
            n_features=n_temporal_features, d_model=d_model, dropout=dropout
        )

        # --- Static context encoding (processed once, injected into temporal path) ---
        self.static_encoder = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        # Static context generates initial hidden state + enrichment vectors
        self.static_to_context = nn.Linear(d_model, d_model * 4)

        # --- Continuous time embedding (not ordinal position) ---
        self.time_embedding = nn.Sequential(
            nn.Linear(1, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, d_model),
        )

        # --- Gated Residual Network layers ---
        self.pre_transformer_grn = GatedResidualNetwork(d_model, dropout=dropout)

        # --- Temporal self-attention (interpretable multi-head) ---
        self.temporal_attention = InterpretableMultiHeadAttention(
            d_model=d_model, n_heads=n_heads, dropout=dropout
        )

        # --- Post-attention processing ---
        self.post_attention_grn = GatedResidualNetwork(d_model, dropout=dropout)
        self.post_attention_norm = nn.LayerNorm(d_model)

        # --- Prediction heads ---
        # Risk classification head
        self.risk_head = nn.Sequential(
            nn.LayerNorm(d_model),
            nn.Linear(d_model, 128),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1),
        )

        # Miss distance regression head (log-scale)
        self.miss_head = nn.Sequential(
            nn.LayerNorm(d_model),
            nn.Linear(d_model, 128),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1),
        )

        # TCA regression head (days)
        self.tca_head = nn.Sequential(
            nn.LayerNorm(d_model),
            nn.Linear(d_model, 64),
            nn.GELU(),
            nn.Linear(64, 1),
        )

    def forward(self, temporal_features, static_features, time_to_tca, mask=None):
        # temporal_features: (B, S, F_t)
        # static_features:   (B, F_s)
        # time_to_tca:       (B, S, 1)

        # 1. Variable selection -- learn which features matter
        temporal_selected, temporal_weights = self.temporal_vsn(temporal_features)
        static_selected, static_weights = self.static_vsn(static_features)

        # 2. Static context -- enrich temporal representations
        static_ctx = self.static_encoder(static_selected)  # (B, D)
        contexts = self.static_to_context(static_ctx)       # (B, 4D)
        c_enrichment, c_state_h, c_state_c, c_signal = contexts.chunk(4, dim=-1)

        # 3. Time embedding -- continuous, handles irregular spacing
        t_embed = self.time_embedding(time_to_tca)  # (B, S, D)
        x = temporal_selected + t_embed              # (B, S, D)

        # 4. Inject static context into temporal path
        x = x + c_enrichment.unsqueeze(1)

        # 5. Gated residual pre-processing
        x = self.pre_transformer_grn(x)

        # 6. Temporal self-attention (returns attention weights for interpretability)
        attended, attn_weights = self.temporal_attention(x, x, x, mask=mask)
        x = self.post_attention_norm(x + attended)
        x = self.post_attention_grn(x)

        # 7. Pool: last timestep (most recent CDM)
        x_last = x[:, -1, :]  # (B, D)

        # 8. Multi-task prediction heads
        risk_logit = self.risk_head(x_last)    # (B, 1)
        miss_log = self.miss_head(x_last)      # (B, 1)
        tca_pred = self.tca_head(x_last)       # (B, 1)

        return risk_logit, miss_log, tca_pred, attn_weights, temporal_weights


class VariableSelectionNetwork(nn.Module):
    """Learns which input features are most relevant via softmax gating."""
    def __init__(self, n_features, d_model, dropout=0.1):
        super().__init__()
        self.feature_transforms = nn.ModuleList([
            nn.Linear(1, d_model) for _ in range(n_features)
        ])
        self.gate = nn.Sequential(
            nn.Linear(n_features * d_model, n_features),
            nn.Softmax(dim=-1),
        )
        self.output_proj = nn.Linear(d_model, d_model)

    def forward(self, x):
        # x: (B, [S,] F) where F = n_features
        # Transform each feature independently, then gate
        ...  # Implementation details in src/model/deep.py


class GatedResidualNetwork(nn.Module):
    """Gated skip connection with ELU activation and layer norm."""
    def __init__(self, d_model, dropout=0.1):
        super().__init__()
        self.fc1 = nn.Linear(d_model, d_model)
        self.fc2 = nn.Linear(d_model, d_model)
        self.gate = nn.Linear(d_model, d_model)
        self.norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, context=None):
        residual = x
        x = F.elu(self.fc1(x))
        x = self.dropout(self.fc2(x))
        gate = torch.sigmoid(self.gate(x))
        return self.norm(residual + gate * x)


class InterpretableMultiHeadAttention(nn.Module):
    """Multi-head attention that shares value weights across heads for interpretability."""
    ...  # See Lim et al. 2021 "Temporal Fusion Transformers"
```

**Physics-Informed Loss Function**:

```python
class PhysicsInformedLoss(nn.Module):
    """
    Combined task loss + physics regularization.

    The physics term penalizes miss distance predictions that violate
    the constraint: predicted miss >= minimum orbital intersection distance (MOID).
    MOID is computed analytically from the two objects' orbital elements.
    If the model predicts a miss distance BELOW the MOID, it gets penalized
    because that trajectory is physically impossible without a maneuver.
    """
    def __init__(self, risk_weight=1.0, miss_weight=0.5, tca_weight=0.3,
                 physics_weight=0.2, pos_weight=50.0):
        super().__init__()
        self.risk_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))
        self.miss_loss = nn.MSELoss()
        self.tca_loss = nn.MSELoss()
        self.risk_weight = risk_weight
        self.miss_weight = miss_weight
        self.tca_weight = tca_weight
        self.physics_weight = physics_weight

    def forward(self, risk_logit, miss_pred_log, tca_pred,
                risk_target, miss_target_log, tca_target,
                moid_km):
        """
        moid_km: Minimum Orbital Intersection Distance for each pair (km).
                 Pre-computed from orbital elements. The miss distance
                 CANNOT be less than MOID unless a maneuver occurs.
        """
        # Standard task losses
        L_risk = self.risk_loss(risk_logit, risk_target)
        L_miss = self.miss_loss(miss_pred_log, miss_target_log)
        L_tca = self.tca_loss(tca_pred, tca_target)

        # Physics constraint: predicted miss >= MOID (in log space)
        moid_log = torch.log1p(moid_km)
        violation = F.relu(moid_log - miss_pred_log)  # Positive when prediction < MOID
        L_physics = violation.mean()

        total = (self.risk_weight * L_risk +
                 self.miss_weight * L_miss +
                 self.tca_weight * L_tca +
                 self.physics_weight * L_physics)

        return total, {
            "risk_loss": L_risk.item(),
            "miss_loss": L_miss.item(),
            "tca_loss": L_tca.item(),
            "physics_loss": L_physics.item(),
        }
```

**Why this architecture**:
- **Variable Selection Networks** automatically discover which CDM features matter most -- publishable finding on its own
- **Static + temporal separation** properly handles object metadata (doesn't change per CDM) vs. observations (change each update)
- **Physics constraint** reduces the effective hypothesis space -- the model can't learn physically impossible relationships, which improves generalization especially on rare high-risk events
- **Interpretable attention** -- attention weights reveal which CDM updates were most informative for each prediction (clinically analogous to "which test results changed the diagnosis")
- **Multi-task heads** force the backbone to learn joint orbital dynamics, not just a single prediction target

**Training details (overnight run on RTX 4070 Ti SUPER)**:
- **Loss**: PhysicsInformedLoss (risk + miss + TCA + physics constraint)
- **Optimizer**: AdamW, lr=3e-4, weight_decay=1e-2
- **Schedule**: Cosine annealing with linear warmup (10% of steps)
- **Batch size**: 128 events (16GB VRAM handles this with mixed precision)
- **Epochs**: 100, early stopping on validation AUC-PR (patience 15)
- **Mixed precision**: torch.cuda.amp for ~2x speedup
- **Gradient accumulation**: 2 steps (effective batch 256)
- **Data split**: 80/10/10 train/val/test, stratified by risk label
- **Estimated training time**: 4-6 hours overnight

**Expected performance**: Significant improvement over vanilla Transformer. The physics constraint should reduce false negatives on high-risk events (the model can't predict "safe" for physically dangerous geometries). Expected AUC-PR ~0.7-0.85.

### 4.4 Bonus Model: Graph Neural Network for Catalog-Wide Kessler Risk

**Location**: `src/model/gnn.py`

**Purpose**: Goes beyond pairwise conjunction prediction to model cascade effects across the full orbital catalog.

**Architecture**: Dynamic heterogeneous graph where:
- **Nodes** = tracked objects (satellites, rocket bodies, debris)
- **Edges** = orbital proximity relationships (altitude overlap + orbital plane similarity)
- **Node features** = orbital elements + object type + maneuverability
- **Edge features** = relative velocity, MOID, angular separation
- **Message passing**: GraphSAGE or GAT layers propagate risk information through the graph
- **Key insight**: If Object A maneuvers to avoid Object B, its new orbit may threaten Object C. The GNN captures this cascade by propagating information through the graph topology.

```python
class KesslerGNN(nn.Module):
    """
    Graph Neural Network for catalog-wide conjunction risk assessment.
    Models cascade effects (Kessler Syndrome) via message passing.
    """
    def __init__(self, node_dim=16, edge_dim=8, hidden_dim=128, n_layers=3):
        super().__init__()
        self.node_encoder = nn.Linear(node_dim, hidden_dim)
        self.edge_encoder = nn.Linear(edge_dim, hidden_dim)
        self.gnn_layers = nn.ModuleList([
            GATv2Conv(hidden_dim, hidden_dim, heads=4, concat=False, edge_dim=hidden_dim)
            for _ in range(n_layers)
        ])
        self.edge_classifier = nn.Sequential(
            nn.Linear(hidden_dim * 2 + hidden_dim, 128),
            nn.GELU(),
            nn.Linear(128, 1),  # per-edge collision risk
        )

    def forward(self, node_features, edge_index, edge_features):
        x = self.node_encoder(node_features)
        e = self.edge_encoder(edge_features)
        for layer in self.gnn_layers:
            x = F.gelu(layer(x, edge_index, edge_attr=e))
        # Edge-level prediction: concat source + target node embeddings + edge features
        src, dst = edge_index
        edge_repr = torch.cat([x[src], x[dst], e], dim=-1)
        risk = self.edge_classifier(edge_repr)
        return risk
```

**Training**: Overnight on GPU, ~4-8 hours depending on graph size.
**Use in app**: Powers the "Kessler Cascade Simulation" feature in the frontend -- shows how one collision could trigger a chain reaction.

### 4.5 Model Comparison Summary

| Model | Input | Sequence-Aware | Training Time | Inference Time | Expected AUC-PR |
|---|---|---|---|---|---|
| Shell Density Prior | altitude only | No | <1s | <1ms | ~0.05 |
| XGBoost (latest CDM + trends) | 60 features | Partial (trend features) | ~30s CPU | <1ms | ~0.5-0.7 |
| PI-TFT (physics-informed) | 40 temporal + 12 static features x 30 steps | Full attention + physics | 4-6hr GPU | ~15ms | ~0.7-0.85 |
| Kessler GNN (bonus) | Full catalog graph | Graph-wide cascade | 4-8hr GPU | ~50ms | TBD |

The deployed model for pairwise predictions will be the PI-TFT. The GNN powers the catalog-wide Kessler simulation feature. XGBoost serves as a fast fallback if the server can't load the Transformer.

### 4.6 Compute Budget

| Task | Hardware | Estimated Time | Estimated Cost |
|---|---|---|---|
| XGBoost training | Local CPU | 30 seconds | $0 |
| PI-TFT training (100 epochs) | Local RTX 4070 Ti SUPER | 4-6 hours overnight | $0 |
| Kessler GNN training | Local RTX 4070 Ti SUPER | 4-8 hours overnight | $0 |
| Hyperparameter sweep (Optuna, 100 trials) | Local GPU | Overnight | $0 |
| Physics loss ablation experiment | Local GPU | 2x training = 8-12 hours | $0 |
| Scale testing / cross-temporal experiments | GCP (GPU instance) | ~4-6 hours | ~$15-25 |
| Foundation model fine-tune comparison (Chronos) | GCP (GPU instance) | ~3-4 hours | ~$10-15 |
| **Total** | | ~2-3 overnights + 1 GCP session | **~$25-40 of $50 credits** |

---

## 5. Experiment: TLE Staleness Sensitivity Analysis

### Motivation
Satellite operators must decide **how frequently to request updated tracking data** from the Space Surveillance Network. Fresh TLEs cost resources (radar time, compute). Stale TLEs introduce orbital prediction error that compounds over time. The question:

> **How does conjunction prediction accuracy degrade as the input TLE data becomes stale?**

This is directly operationally relevant: it tells operators the maximum acceptable TLE age before predictions become unreliable.

### Methodology

We simulate TLE staleness by **truncating CDM sequences** at progressively earlier cutoff times before TCA:

```
Full sequence:     [CDM_7d, CDM_5d, CDM_3d, CDM_2d, CDM_1d, CDM_12h, CDM_6h, CDM_2h]
                                                                                 ↑ TCA

Simulated staleness experiments:
  2-hour stale:    [CDM_7d, CDM_5d, CDM_3d, CDM_2d, CDM_1d, CDM_12h, CDM_6h, CDM_2h]  (full)
  6-hour stale:    [CDM_7d, CDM_5d, CDM_3d, CDM_2d, CDM_1d, CDM_12h, CDM_6h]
  12-hour stale:   [CDM_7d, CDM_5d, CDM_3d, CDM_2d, CDM_1d, CDM_12h]
  1-day stale:     [CDM_7d, CDM_5d, CDM_3d, CDM_2d, CDM_1d]
  2-day stale:     [CDM_7d, CDM_5d, CDM_3d, CDM_2d]
  3-day stale:     [CDM_7d, CDM_5d, CDM_3d]
  5-day stale:     [CDM_7d, CDM_5d]
  7-day stale:     [CDM_7d]
```

For each staleness level, we evaluate all three models on the same test set and record:
- AUC-PR (primary metric for risk classification)
- AUC-ROC
- Miss distance MAE (km)
- Miss distance MAE on log scale
- False negative rate at a fixed decision threshold

### Hypotheses
1. **Naive baseline is unaffected** — it doesn't use CDM data, only altitude
2. **XGBoost degrades gracefully** — trend features become noisier but latest CDM features still work
3. **Transformer degrades faster for short sequences** (less context) but may be more robust at medium staleness (2-3 days) where attention over sparse data matters
4. **Critical threshold**: We expect a sharp performance knee around 1-2 days, beyond which predictions become operationally unreliable

### Visualization
- Line plot: AUC-PR vs. staleness (hours) for all three models
- Heatmap: per-altitude-band accuracy vs. staleness
- Error distribution: miss distance prediction error histograms at each staleness level

### Publication Angle
No existing paper quantifies the ML performance degradation curve as a function of data staleness for conjunction assessment. This fills a real gap -- operators currently use rules of thumb ("TLEs older than 3 days are suspect"). We can provide data-driven guidance.

### 5.2 Secondary Experiment: Physics Loss Ablation

**Question**: Does embedding orbital mechanics constraints into the loss function improve conjunction prediction over a standard data-driven Transformer?

**Methodology**: Train two identical PI-TFT models:
- **Model A**: Full PhysicsInformedLoss (risk + miss + TCA + physics constraint)
- **Model B**: Standard loss only (risk + miss + TCA, physics_weight=0.0)

Same architecture, same hyperparameters, same data, same random seed. Only difference is the physics regularization term.

**Evaluate on**:
- Overall AUC-PR and miss distance MAE
- Performance on **rare high-risk events** specifically (does the constraint help where it matters most?)
- Physical plausibility: how often does each model predict miss distances below the analytic MOID?
- Generalization: train on 2015-2017 data, test on 2018-2019 (temporal holdout)

**Hypotheses**:
1. Physics constraint reduces physically impossible predictions by >50%
2. Overall AUC-PR improves modestly (~2-5%)
3. The big win is on generalization: physics-informed model degrades less on future (unseen-year) data because orbital mechanics don't change over time
4. Variable selection weights shift when physics loss is added -- the model attends more to orbital elements and less to raw CDM statistics

**Hardware**: 2x overnight training runs on local GPU, or 1 session on GCP with both running in parallel (~$10-15).

**Publication angle**: "Does Physics-Informed Deep Learning Improve Orbital Conjunction Assessment?" -- clean A/B study, novel application of PINNs to SSA, directly actionable for operators.

---

## 6. Application Architecture

### Overview

```
┌──────────────────────────────────────────────────────────────────────┐
│                        User's Browser                                │
│                                                                      │
│  ┌──────────────────────────────────────────────────────────────┐    │
│  │  React 19 + TypeScript + Tailwind CSS 4                      │    │
│  │                                                              │    │
│  │  ┌───────────────┐  ┌────────────────┐  ┌────────────────┐  │    │
│  │  │  3D Globe      │  │  Conjunction   │  │  Risk          │  │    │
│  │  │  (Three.js /   │  │  Alert Panel   │  │  Dashboard     │  │    │
│  │  │  R3F)          │  │                │  │                │  │    │
│  │  │                │  │  - Top 10 pairs│  │  - Density map │  │    │
│  │  │  - 30k objects │  │  - Countdown   │  │  - Risk by alt │  │    │
│  │  │  - satellite.js│  │  - Miss dist.  │  │  - Trends      │  │    │
│  │  │  - Click info  │  │  - Risk score  │  │  - Statistics  │  │    │
│  │  │  - Time slider │  │  - Maneuver    │  │                │  │    │
│  │  └───────────────┘  └────────────────┘  └────────────────┘  │    │
│  │                                                              │    │
│  │  ┌────────────────────────────────────────────────────────┐  │    │
│  │  │  Object Search / Filter Bar                            │  │    │
│  │  │  [Search by name/NORAD ID] [Filter: type, altitude,   │  │    │
│  │  │   country, constellation] [Model selector]             │  │    │
│  │  └────────────────────────────────────────────────────────┘  │    │
│  └──────────────────────────────────────────────────────────────┘    │
│                              │ API calls                             │
└──────────────────────────────┼───────────────────────────────────────┘
                               │ HTTPS (Cloudflare Tunnel)
                               ▼
┌──────────────────────────────────────────────────────────────────────┐
│                     FastAPI Inference Server                          │
│                  (GitHub Actions Runner)                              │
│                                                                      │
│  POST /api/predict-conjunction                                       │
│    Input: object_pair orbital elements + CDM history                 │
│    Output: risk_probability, predicted_miss_distance, urgency_tier   │
│                                                                      │
│  GET /api/bulk-screen                                                │
│    Input: list of TLEs for N objects                                 │
│    Output: top-K highest risk pairs with scores                      │
│                                                                      │
│  GET /api/health                                                     │
│    Output: model loaded, device, inference mode                      │
│                                                                      │
│  Models loaded at startup from HuggingFace Hub:                      │
│    - XGBoost risk classifier + miss regressor (.pkl)                 │
│    - Temporal Transformer (.pt state dict)                           │
│    - Shell density baseline (JSON lookup table)                      │
└──────────────────────────────────────────────────────────────────────┘
```

### Key Design Principles
1. **Heavy client, light server**: All orbital propagation happens in the browser via `satellite.js`. The server is only needed for ML inference on specific conjunction pairs. This means the 3D visualization works even if the inference server is momentarily down.
2. **Progressive enhancement**: The globe loads and renders immediately from cached TLEs. ML predictions are fetched asynchronously and overlaid.
3. **Inference-only backend**: No training, no data processing, no database. Just model loading + prediction. Keeps the GitHub Actions runner lightweight.

---

## 7. Frontend: 3D Orbital Visualization

### Technology Stack
- **React 19** + TypeScript
- **React Three Fiber (R3F)** — React renderer for Three.js
- **@react-three/drei** — Helper components (OrbitControls, Stars, Html overlays)
- **satellite.js** — SGP4 propagation from TLEs
- **Tailwind CSS 4** — Utility-first styling
- **Radix UI** — Accessible primitives for panels, dialogs, tooltips
- **Recharts** or **Nivo** — Dashboard charts (density histograms, risk timelines)
- **Vite 7** — Build tool

### 3D Globe Features

**Earth rendering**:
- Textured sphere with day/night terminator line
- Atmospheric glow (Fresnel shader)
- Country borders (GeoJSON overlay, optional)
- Longitude/latitude grid lines (toggleable)

**Object rendering**:
- Each tracked object = instanced point (InstancedMesh for performance with 30k objects)
- Color by category:
  - Green: active payload (operational satellite)
  - Yellow: rocket body
  - Red: debris fragment
  - White: unknown/unclassified
  - Pulsing orange: objects involved in predicted conjunctions
- Size scaled by altitude (closer = slightly larger for depth cue)
- At 30k objects, instanced rendering keeps it at 60fps

**Orbit trail rendering**:
- Click any object → render its full orbit as a line (one orbital period)
- For conjunction pairs: render both orbits + highlight the intersection zone
- Trail color gradient: brighter near the object, fading behind

**Time controls**:
- Play/pause real-time propagation
- Time scrubber: drag to propagate all objects to any time ±7 days
- Speed multiplier: 1x, 10x, 100x, 1000x
- "Jump to next conjunction" button

**Interaction**:
- Click any object → info panel slides in from right:
  - Object name, NORAD ID, international designator
  - Orbit type (LEO/MEO/GEO), altitude, inclination
  - Operator, purpose (from UCS data if available)
  - Upcoming conjunctions involving this object
  - Link to Space-Track page
- Hover → tooltip with name + altitude
- Search bar: type name or NORAD ID → camera flies to object
- Filter panel: filter by type, altitude range, country, constellation

### Dashboard Panels (alongside globe)

**Conjunction Alerts** (right sidebar):
- Table of top 10 highest-risk conjunction pairs in the next 7 days
- Each row: Object 1 name, Object 2 name, TCA countdown, predicted miss distance, risk score (color-coded)
- Click any row → globe camera flies to the conjunction point, renders both orbits
- Expandable detail: CDM history chart, model prediction breakdown, recommended action

**Orbital Density View** (toggleable overlay):
- Altitude histogram: bar chart showing object count per 50km altitude band
- Heatmap mode: globe surface colored by overhead debris density
- Kessler risk indicator: which altitude bands are approaching critical density

**Risk Timeline** (bottom panel):
- Time-series chart of aggregate conjunction risk over the next 7 days
- Each spike = a predicted close approach
- Hovering over a spike highlights the pair on the globe

**Model Comparison Panel** (accessible via settings):
- Side-by-side predictions from all three models for any selected conjunction
- Shows baseline vs. XGBoost vs. Transformer predictions
- Confidence intervals where available

### Performance Optimization
- **InstancedMesh**: Render 30k points as a single draw call (not 30k separate meshes)
- **LOD (Level of Detail)**: Far-away objects = points; zoomed-in objects = spheres with labels
- **Web Workers**: Propagate TLEs in a worker thread to avoid blocking the UI
- **Lazy loading**: Load debris groups on demand (don't fetch all 30k TLEs on page load)
- **Frame budget**: Target 60fps; reduce to 30fps on mobile; LOD scales with device

---

## 8. Backend: FastAPI Inference Server

### Endpoints

```python
# app/main.py

@app.get("/api/health")
async def health():
    """Returns server status, loaded models, device info."""

@app.post("/api/predict-conjunction")
async def predict_conjunction(request: ConjunctionRequest):
    """
    Given orbital elements for two objects + optional CDM history,
    predict collision risk and miss distance.

    Input:
    {
        "object_1": { "norad_id": 25544, "tle_line1": "...", "tle_line2": "..." },
        "object_2": { "norad_id": 33757, "tle_line1": "...", "tle_line2": "..." },
        "cdm_history": [ ... ],  // optional: prior CDM snapshots
        "model": "transformer"   // or "xgboost" or "baseline" or "ensemble"
    }

    Output:
    {
        "risk_probability": 0.73,
        "predicted_miss_distance_km": 0.45,
        "urgency_tier": "HIGH",
        "recommendation": "Maneuver advisory: consider delta-v adjustment...",
        "model_used": "transformer",
        "attention_weights": [ ... ],  // which CDMs mattered most
        "all_model_predictions": {
            "baseline": { "risk": 0.02, "miss_km": 12.4 },
            "xgboost": { "risk": 0.68, "miss_km": 0.52 },
            "transformer": { "risk": 0.73, "miss_km": 0.45 }
        },
        "disclaimer": "IMPORTANT: This is a research tool..."
    }
    """

@app.get("/api/bulk-screen")
async def bulk_screen(group: str = "active", top_k: int = 10):
    """
    Screen all pairs in a TLE group for conjunction risk.
    Returns top-K highest risk pairs.

    Uses pre-computed pairwise screening (orbital mechanics filter)
    to reduce O(N^2) pairs to a manageable candidate set, then
    runs ML inference on candidates only.
    """

@app.get("/api/object-info/{norad_id}")
async def object_info(norad_id: int):
    """
    Return enriched metadata for an object (UCS + TLE data).
    """
```

### Pairwise Screening (Reducing O(N^2))

With 30k objects, there are ~450M possible pairs. We can't run ML on all of them. Standard approach:

1. **Apogee/Perigee filter**: Two objects can only collide if their altitude bands overlap. This eliminates ~99% of pairs.
2. **RAAN filter**: Objects in very different orbital planes rarely intersect. Filter pairs where `|RAAN_1 - RAAN_2|` adjusted for precession exceeds threshold.
3. **Coplanar geometry check**: For remaining pairs, compute minimum orbit intersection distance (MOID) analytically.
4. **ML inference**: Only for pairs passing all filters (~hundreds to low thousands).

This is implemented server-side in Python using vectorized numpy operations.

### Model Loading

```python
# app/main.py startup

@app.on_event("startup")
async def load_models():
    # 1. Download from HuggingFace Hub (or use local cache)
    model_dir = download_models_from_hf(
        repo_id="<user>/panacea-orbital-models",
        revision="v1",
    )

    # 2. Load all three models
    app.state.baseline = OrbitalShellBaseline.load(model_dir / "baseline.json")
    app.state.xgboost = XGBoostConjunctionModel.load(model_dir / "xgboost_risk.pkl")
    app.state.transformer = ConjunctionTransformer.load(model_dir / "transformer.pt")

    # 3. Load UCS metadata for enrichment
    app.state.ucs_data = load_ucs_database(model_dir / "ucs_satellites.csv")
```

### Triage System

```python
class ConjunctionTriage:
    """Three-tier urgency system for conjunction events."""

    THRESHOLDS = {
        "LOW":      {"max_risk": 0.10, "color": "green"},
        "MODERATE": {"max_risk": 0.40, "color": "amber"},
        "HIGH":     {"max_risk": 1.00, "color": "red"},
    }

    RECOMMENDATIONS = {
        "LOW":      "No action required. Continue monitoring.",
        "MODERATE": "Enhanced tracking recommended. Prepare contingency maneuver plan.",
        "HIGH":     "Maneuver advisory. Immediate conjunction assessment recommended.",
    }
```

---

## 9. Deployment & Hosting

### Architecture (replicated from SkinTag, $0 total cost)

```
┌─────────────────┐     ┌─────────────────────────┐     ┌─────────────────┐
│  GitHub Pages   │     │  GitHub Actions Runner   │     │  HuggingFace    │
│  (React App)    │────▶│  FastAPI + Cloudflare    │────▶│  Hub            │
│  Static HTTPS   │     │  Tunnel                  │     │  Model Weights  │
│  Free           │     │  Free (ping-pong A/B)    │     │  Free           │
└─────────────────┘     └─────────────────────────┘     └─────────────────┘
        ▲                          ▲
        │                          │
        └──── git notes ───────────┘
              (API URL sharing)
```

### GitHub Actions Workflows

**1. `deploy-webapp.yml`** — Frontend deployment
- Trigger: push to `webapp-react/` or manual
- Builds React app with Vite, injects VITE_API_URL from git notes
- Deploys to GitHub Pages

**2. `inference-server-a.yml`** / **`inference-server-b.yml`** — Ping-pong inference
- Configurable duration (default 5 hours)
- Downloads models from HuggingFace Hub
- Starts FastAPI via uvicorn
- Cloudflare tunnel for public HTTPS
- Stores tunnel URL in git notes
- At timeout - 6min, triggers sibling workflow → seamless handoff

**3. `train.yml`** — Model training (manual dispatch)
- Downloads ESA Kelvins data from Zenodo
- Trains all three models
- Uploads artifacts (7-day retention) + pushes weights to HuggingFace Hub

**4. `claude.yml`** — Claude Code integration for PRs/issues

### Requirements Files

**requirements.txt** (full, for training):
```
torch>=2.0
scikit-learn>=1.3
xgboost>=2.0
pandas>=2.0
numpy>=1.24
pyyaml>=6.0
tqdm>=4.65
matplotlib>=3.7
seaborn>=0.12
jupyter>=1.0
```

**requirements-inference.txt** (minimal, for deployment):
```
torch>=2.0
scikit-learn>=1.3
xgboost>=2.0
numpy>=1.24
fastapi>=0.104
uvicorn>=0.24
python-multipart>=0.0.6
huggingface-hub>=0.20
pyyaml>=6.0
```

---

## 10. Repository Structure

```
Panacea/
├── .github/
│   ├── workflows/
│   │   ├── deploy-webapp.yml
│   │   ├── inference-server-a.yml
│   │   ├── inference-server-b.yml
│   │   ├── train.yml
│   │   └── claude.yml
│   └── CODEOWNERS
│
├── src/
│   ├── __init__.py
│   ├── data/
│   │   ├── __init__.py
│   │   ├── cdm_loader.py          # Load & parse ESA Kelvins CDM CSVs
│   │   ├── feature_eng.py         # Engineered features for classical ML
│   │   ├── sequence_builder.py    # Build CDM sequences for Transformer
│   │   ├── tle_fetcher.py         # Fetch live TLEs from CelesTrak
│   │   └── ucs_loader.py          # Load UCS satellite metadata
│   │
│   ├── model/
│   │   ├── __init__.py
│   │   ├── baseline.py            # Orbital shell density prior
│   │   ├── classical.py           # XGBoost risk + miss distance
│   │   ├── deep.py                # Temporal Transformer
│   │   └── triage.py              # Urgency tier system
│   │
│   ├── evaluation/
│   │   ├── __init__.py
│   │   ├── metrics.py             # AUC-PR, AUC-ROC, MAE, per-group metrics
│   │   └── staleness.py           # TLE staleness experiment
│   │
│   └── utils/
│       ├── __init__.py
│       ├── model_hub.py           # HuggingFace Hub upload/download
│       └── config.py              # YAML config loader
│
├── app/
│   ├── __init__.py
│   └── main.py                    # FastAPI inference server
│
├── webapp-react/
│   ├── src/
│   │   ├── App.tsx
│   │   ├── main.tsx
│   │   ├── components/
│   │   │   ├── Globe.tsx           # React Three Fiber 3D Earth
│   │   │   ├── SatelliteLayer.tsx  # Instanced satellite points
│   │   │   ├── OrbitTrail.tsx      # Orbital path line rendering
│   │   │   ├── ConjunctionAlert.tsx # Alert panel
│   │   │   ├── RiskDashboard.tsx   # Charts & statistics
│   │   │   ├── ObjectInfoPanel.tsx # Object detail sidebar
│   │   │   ├── TimeControls.tsx    # Play/pause/scrub controls
│   │   │   ├── SearchFilter.tsx    # Object search & filtering
│   │   │   └── ModelComparison.tsx # Side-by-side model outputs
│   │   ├── hooks/
│   │   │   ├── useSatellites.ts    # TLE fetch + satellite.js propagation
│   │   │   ├── useConjunctions.ts  # API calls for predictions
│   │   │   └── useTimeControl.ts   # Simulation time management
│   │   ├── lib/
│   │   │   ├── orbital.ts          # satellite.js wrapper utilities
│   │   │   ├── api.ts              # Backend API client
│   │   │   └── types.ts            # TypeScript interfaces
│   │   └── styles/
│   │       └── globals.css
│   ├── public/
│   │   ├── textures/               # Earth day/night/bump maps
│   │   └── data/                   # Cached TLE snapshots for offline
│   ├── index.html
│   ├── vite.config.ts
│   ├── tailwind.config.ts
│   ├── tsconfig.json
│   └── package.json
│
├── scripts/
│   ├── download_cdm.py            # Download ESA Kelvins from Zenodo
│   ├── fetch_tles.py              # Snapshot current TLEs
│   ├── fetch_ucs.py               # Download UCS database
│   ├── train.py                   # Train all three models
│   ├── evaluate.py                # Full evaluation suite
│   └── run_experiment.py          # TLE staleness experiment
│
├── notebooks/
│   ├── eda_cdm.ipynb              # Exploratory data analysis on CDMs
│   ├── eda_orbits.ipynb           # Orbital environment analysis
│   ├── model_comparison.ipynb     # Side-by-side model evaluation
│   └── experiment_results.ipynb   # Staleness experiment visualization
│
├── configs/
│   └── config.yaml                # Model, training, triage thresholds
│
├── data/                          # (gitignored)
│   ├── cdm/
│   ├── tle/
│   └── ucs/
│
├── models/                        # (gitignored)
│   ├── baseline.json
│   ├── xgboost_risk.pkl
│   ├── xgboost_miss.pkl
│   └── transformer.pt
│
├── results/                       # (gitignored)
│
├── Dockerfile
├── Dockerfile.gpu
├── Makefile
├── requirements.txt
├── requirements-inference.txt
├── CLAUDE.md
├── PLAN.md                        # This file
├── README.md
├── .gitignore
└── LICENSE
```

---

## 11. Development Phases

### Phase 1: Foundation (Data + Baseline)
- [ ] Set up repository structure, .gitignore, Makefile
- [ ] Write `scripts/download_cdm.py` — download ESA Kelvins from Zenodo
- [ ] Write `src/data/cdm_loader.py` — parse CDM CSVs into ConjunctionEvent dataclass
- [ ] Exploratory data analysis notebook (`notebooks/eda_cdm.ipynb`)
- [ ] Implement `src/model/baseline.py` — orbital shell density prior
- [ ] Implement `src/evaluation/metrics.py` — AUC-PR, AUC-ROC, MAE
- [ ] Evaluate baseline, document results
- **Branch**: `feature/data-pipeline`

### Phase 2: Classical ML Model
- [ ] Write `src/data/feature_eng.py` — engineer 60+ features from CDM sequences
- [ ] Implement `src/model/classical.py` — XGBoost dual-head (risk + miss distance)
- [ ] Hyperparameter tuning (Optuna or manual grid)
- [ ] Evaluate, compare to baseline
- [ ] Feature importance analysis
- **Branch**: `feature/xgboost-model`

### Phase 3: Deep Learning Model
- [ ] Write `src/data/sequence_builder.py` — CDM sequence padding/truncation
- [ ] Implement `src/model/deep.py` — Temporal Transformer
- [ ] Training loop with early stopping, mixed precision
- [ ] Evaluate, compare all three models
- [ ] Extract attention weights for interpretability
- **Branch**: `feature/transformer-model`

### Phase 4: Experiment
- [ ] Implement `src/evaluation/staleness.py` — TLE staleness simulation
- [ ] Write `scripts/run_experiment.py` — orchestrate experiment across staleness levels
- [ ] Generate experiment visualizations
- [ ] Write up results and interpretation
- **Branch**: `feature/staleness-experiment`

### Phase 5: Backend API
- [ ] Implement `app/main.py` — FastAPI with all endpoints
- [ ] Implement model loading from HuggingFace Hub
- [ ] Implement pairwise screening (apogee/perigee + RAAN filter)
- [ ] Implement triage system
- [ ] Test locally
- **Branch**: `feature/api-server`

### Phase 6: Frontend — 3D Globe
- [ ] Scaffold React + R3F + Vite project
- [ ] Implement Earth sphere with textures
- [ ] Integrate satellite.js for TLE propagation
- [ ] Implement InstancedMesh for 30k objects
- [ ] Add OrbitControls, camera, lighting
- [ ] Implement click interaction + object info panel
- [ ] Implement time controls (play/pause/scrub)
- [ ] Implement orbit trail rendering
- **Branch**: `feature/3d-globe`

### Phase 7: Frontend — Dashboard + Panels
- [ ] Conjunction alert panel (top-10 table)
- [ ] Risk dashboard (density charts, altitude histograms)
- [ ] Search/filter bar
- [ ] Model comparison panel
- [ ] Dark mode, responsive layout
- [ ] Loading states, error handling, empty states
- **Branch**: `feature/dashboard`

### Phase 8: Deployment
- [ ] Upload trained models to HuggingFace Hub
- [ ] Set up GitHub Actions workflows (all 4)
- [ ] Configure Cloudflare tunnel in inference workflows
- [ ] Implement git notes API URL sharing
- [ ] Deploy frontend to GitHub Pages
- [ ] Test full end-to-end: frontend → tunnel → inference → response
- [ ] Verify 1-week uptime with ping-pong handoff
- **Branch**: `feature/deployment`

### Phase 9: Polish & Documentation
- [ ] README.md with screenshots, architecture diagram, live demo link
- [ ] Notebook: final model comparison with publication-quality figures
- [ ] Notebook: experiment results write-up
- [ ] Performance optimization (60fps target, mobile fallbacks)
- [ ] Edge case handling (server down, no TLE data, etc.)
- **Branch**: `feature/polish`

---

## 12. Evaluation & Metrics

### Primary Metrics

| Metric | Task | Why |
|---|---|---|
| **AUC-PR** | Risk classification | Primary. Handles severe class imbalance (<<2% positive). Precision-recall is more informative than ROC when positives are rare. |
| AUC-ROC | Risk classification | Secondary. Reported for comparability with literature. |
| F1 (risk class) | Risk classification | At chosen operating threshold. |
| Recall @ Fixed Precision | Risk classification | "At 50% precision, what recall do we achieve?" Operationally relevant. |
| MAE (log km) | Miss distance regression | Log-scale because distances span orders of magnitude. |
| MAE (km) | Miss distance regression | Interpretable absolute error. |
| RMSE (log km) | Miss distance regression | Penalizes large errors more. |

### Per-Group Evaluation
- **By altitude regime**: LEO (<2000km), MEO (2000-35000km), GEO (~35786km)
- **By object type pair**: Payload-Payload, Payload-Debris, Debris-Debris, Payload-RocketBody
- **By CDM sequence length**: Short (2-5 CDMs), Medium (6-15), Long (16+)
- **By time-to-TCA at prediction**: How far out can we predict reliably?

### Operating Point Selection
For a deployed screening tool, we want **high recall** (don't miss real threats) at **acceptable precision** (don't overwhelm operators with false alarms).

Target: **90% recall at maximum achievable precision** on the risk class. Report the threshold and precision at this operating point.

---

## 13. Risk Analysis & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|---|---|---|---|
| ESA Kelvins data is anonymized — can't link to real objects | Certain | Medium | Training uses Kelvins; live demo uses CelesTrak TLEs with simulated CDM-like features. Clearly document this distinction. |
| 30k objects at 60fps may lag on low-end devices | Medium | Medium | InstancedMesh, LOD, Web Workers, mobile fallback to 5k objects. Progressive loading. |
| Transformer overfits on small positive class | Medium | High | Heavy regularization (dropout 0.3), class weighting, early stopping on AUC-PR. Data augmentation via CDM sequence sub-sampling. |
| CelesTrak API rate limits or downtime | Low | Medium | Cache daily TLE snapshots in `public/data/`. Fallback to cached data. |
| GitHub Actions runner too slow for Transformer inference | Low | Medium | Transformer is small (~3M params). CPU inference ~10ms per event. If needed, serve XGBoost only (<<1ms). |
| Cloudflare tunnel URL changes on restart | Certain | Low | Git notes pattern (from SkinTag) handles this automatically. |
| HuggingFace Hub rate limits | Low | Low | Models cached after first download. Hub only hit on cold start. |
| Class imbalance makes training unstable | Medium | High | Focal loss, oversampling, threshold tuning on validation set. Report AUC-PR not accuracy. |

---

## Appendix A: Key References

### Datasets
- ESA Kelvins Collision Avoidance Challenge: https://kelvins.esa.int/collision-avoidance-challenge/
- Kelvins CDM Dataset (Zenodo): https://zenodo.org/records/4463683
- CelesTrak GP Data: https://celestrak.org/NORAD/elements/
- UCS Satellite Database: https://www.ucsusa.org/resources/satellite-database
- Space-Track.org: https://www.space-track.org/

### Libraries
- satellite.js (SGP4 propagation): https://github.com/shashwatak/satellite-js
- React Three Fiber: https://docs.pmnd.rs/react-three-fiber
- Three.js: https://threejs.org/
- FastAPI: https://fastapi.tiangolo.com/

### Literature
- Uriot, T. et al. (2022). "Spacecraft Collision Avoidance Challenge." *Journal of Space Safety Engineering*.
- Pinto, F. et al. (2020). "Towards Automated Satellite Conjunction Management with Bayesian Deep Learning."
- Acciarini, G. et al. (2021). "Kessler Syndrome: A Challenge for Space Situational Awareness."
- Kelso, T.S. (2007). "Validation of SGP4 and IS-GPS-200D Against GPS Precision Ephemerides."

### SkinTag Patterns (reference implementation)
- Dual ping-pong inference servers: `.github/workflows/inference-server-a.yml`
- Git notes API URL sharing: deploy-webapp.yml + inference-server-a.yml
- HuggingFace Hub model hosting: `src/utils/model_hub.py`
- React + Vite + Tailwind frontend: `webapp-react/`
