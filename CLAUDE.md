<!-- Generated by Claude Code (Claude Opus 4.6) — 2026-02-07 -->

# Panacea - CLAUDE.md

## Project Context
**Course**: AIPI 540 - Deep Learning Applications (Duke University)
**Type**: Individual Final Project (20% of course grade)
**Demo Day**: April 21, 2026
**Developer**: Dominic Tanzillo (Medical Student)

## Project Requirements Checklist
- [ ] Three modeling approaches: naive baseline, classical ML, deep learning neural network
- [ ] At least one focused experiment (sensitivity, robustness, ablation, etc.)
- [ ] Interactive, publicly accessible web application (live 1+ week after submission)
- [ ] Inference only in app (no training)
- [ ] Product-level UX (not a basic Streamlit app)
- [ ] Must be NEW work (not reused from SkinTag or other projects)
- [ ] All three models documented with clear location pointers in repo

## Course Modules Covered
- Week 1: Intro to Neural Networks
- Weeks 2-5: Computer Vision (CNNs, Transfer Learning, Data Augmentation)
- Weeks 6-10: NLP (Representations, Transformers, Attention, Sequence Models)
- Weeks 11-12: Generative AI (GANs, VAEs, Diffusion Models)
- Weeks 13-14: Recommendation Systems (Content, Collaborative, Hybrid, Deep)
- Week 15: Demo Day

## Architecture Patterns (from SkinTag)

### GitHub Actions - Dual Ping-Pong Inference Servers
**Problem**: GitHub Actions has ~5-hour timeout limit.
**Solution**: Two workflows (inference-server-a.yml / inference-server-b.yml) hand off:
- Server A runs for ~5 hours, monitoring elapsed time every 30 seconds
- At ~6 minutes remaining, triggers Server B workflow via `gh workflow run`
- Server A cancels itself to free resource slots
- Server B repeats the cycle, triggering Server A when its timer expires
- **Result**: Continuous 24/7 free inference hosting

**Key implementation details**:
- Configurable DURATION_SECONDS (default 18000 = 5 hours, max 19800 = 5.5 hours)
- Health checks: polls `/api/health` up to 60 times on startup
- Graceful handoff: 30-second wait before canceling predecessor
- Model download from HuggingFace Hub with HF_TOKEN authentication
- Cloudflare Tunnel (`cloudflared`) for public HTTPS endpoint

### Git Notes for Dynamic API URL Sharing
**Problem**: Frontend needs to know inference server URL, which changes on each restart.
**Solution**: Use git notes on the first commit as a key-value store:
```bash
# Server writes tunnel URL to git notes
git notes add -f -m "$TUNNEL_URL" $(git rev-list --max-parents=0 HEAD)

# Frontend build reads it
TUNNEL_URL=$(git notes show $(git rev-list --max-parents=0 HEAD))
VITE_API_URL=$TUNNEL_URL npm run build
```
- No centralized config needed - git itself becomes the state store
- Frontend workflow fetches notes with `fetch-depth: 0` for full history

### Frontend Deployment (GitHub Pages)
- React + TypeScript + Vite build → GitHub Pages
- Triggered on push to webapp directory or manual dispatch
- Reads API URL from git notes → embeds as VITE_API_URL env var
- Concurrency control: serializes page deployments (cancel-in-progress: false)
- Free HTTPS at `<org>.github.io/<repo>/`

### Claude Code GitHub Integration
- `.github/workflows/claude.yml` triggers on @claude mentions in PRs/issues
- Anthropic Claude Code automation for code review and task automation
- Read-only on code/PRs, write access for CI result reading

### Model Hosting on HuggingFace Hub
- Gated repo with HF_TOKEN authentication
- Revision-based versioning (e.g., `v2-field-augmented`)
- `snapshot_download()` with `allow_patterns` for selective file download
- Local cache fallback at `~/.cache/huggingface/hub/`
- Separate requirements-inference.txt for minimal deployment dependencies

### Configurable Cache Invalidation
- MD5 hash of augmentation/config JSON → append to cache filename
- Automatic recomputation when config changes, no manual cache busting
```python
config_hash = hashlib.md5(json.dumps(config, sort_keys=True).encode()).hexdigest()[:8]
cache_path = base_path.with_name(f"{base_path.stem}_{config_hash}.pt")
```

### Lazy Image Loading
- Store file paths in dataclass, not loaded images
- Load on-demand during batch processing
- Reduced RAM from ~25GB to <4GB for 47k image dataset

### Unified Schema Pattern
- Single dataclass (e.g., `SkinSample`) with optional fields
- Per-dataset adapters convert raw CSV formats to unified schema
- Eliminates per-dataset branching throughout entire pipeline

### Combined Balanced Sampling
- Multiplicative weight composition for independent bias correction
- Domain weights x demographic weights → simultaneous mitigation
- Normalize to sum to N for proper sampling

## Tech Stack Reference

### Backend
- **FastAPI** + **uvicorn** (REST API, ASGI server)
- **python-multipart** (file upload support)
- CORS configured for GitHub Pages + localhost origins

### Frontend
- **React 19** + **TypeScript** + **Vite 7** + **Tailwind CSS 4**
- **Radix UI** (accessible component library, WCAG compliant)
- **react-easy-crop** (image cropping), **MediaPipe** (hand detection for camera)
- Dark mode with localStorage persistence
- Mobile-first responsive design
- LocalStorage-based analysis history

### ML/DL
- **PyTorch 2.0+** (primary DL framework)
- **transformers 4.40+** (HuggingFace models: SigLIP, ViT, DenseNet, etc.)
- **scikit-learn 1.3+** (classical ML: LogReg, MLP, Pipeline, StandardScaler)
- **XGBoost 2.0+** (gradient boosted trees - excellent on embeddings)
- **albumentations 1.3+** (image augmentation pipelines)

### DevOps
- **Docker** (CPU and GPU variants)
- **Cloudflare Tunnel** (free HTTPS tunneling)
- **GitHub Actions** (CI/CD, inference hosting, model training)
- **GitHub Pages** (frontend hosting)
- **HuggingFace Hub** (model artifact storage)
- **Makefile** (build automation with 50+ targets)

### Data
- **pandas**, **numpy**, **Pillow**, **opencv-python-headless**
- **PyYAML** (config management), **tqdm** (progress bars)

## Deployment Architecture Summary
```
[GitHub Pages]           [GitHub Actions Runner]          [HuggingFace Hub]
  React 19 App    <-->    FastAPI + uvicorn         <-->   Model Weights
  Vite build              Cloudflare Tunnel                Gated Repo
  Static HTTPS            Dynamic HTTPS                    Version Control
       |                       |                                |
       +--- git notes ---------+                                |
                               +--- hf_hub.snapshot_download ---+
```

**Cost**: $0 (GitHub Actions free tier + GitHub Pages + HF Hub free + Cloudflare free tunnel)

## Evaluation Framework Reference
- **Primary metric**: F1 Macro (handles class imbalance correctly)
- **Fairness metrics**: Equalized odds gap, per-group sensitivity/specificity
- **Cross-domain evaluation**: Leave-one-domain-out experiments
- **Robustness testing**: 12 distortion types (noise, blur, brightness, rotation, compression)
- **Per-dataset performance**: Break down by source dataset
- **Ablation studies**: Frozen vs fine-tuned embeddings, augmentation impact

## Agent Attribution Policy
- All code generated via Claude Code or any AI agent MUST include a timestamp and attribution
- Format for file headers: `# Generated by Claude Code — YYYY-MM-DD`
- Format for commits: include `Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>` in commit message
- Format for substantial generated sections in docs: `<!-- Generated by Claude Code — YYYY-MM-DD -->`
- This policy exists for transparency and academic integrity tracking
- Remove this requirement only when the developer explicitly says so

## Git Workflow
- **ALWAYS create feature branches** - never commit directly to main
- Branch naming: `feature/<description>`, `fix/<description>`, `experiment/<description>`
- Merge into main via PR (even solo development) for rollback safety
- Every logical chunk of work gets its own branch → PR → merge
- This ensures clean `git revert` and `git bisect` capability at all times
- Keep commits atomic and well-described
- **Use Gitmoji** in commit messages. Common ones:
  - :sparkles: `:sparkles:` New feature
  - :bug: `:bug:` Bug fix
  - :recycle: `:recycle:` Refactor
  - :memo: `:memo:` Documentation
  - :rocket: `:rocket:` Deploy
  - :wrench: `:wrench:` Config/tooling
  - :chart_with_upwards_trend: `:chart_with_upwards_trend:` Analytics/experiments
  - :art: `:art:` UI/style
  - :tada: `:tada:` Initial commit / milestone
  - :construction: `:construction:` Work in progress
  - :white_check_mark: `:white_check_mark:` Tests
  - :package: `:package:` Dependencies

## Code Style
- Python: PEP 8, type hints preferred
- TypeScript: strict mode, functional components
- Config: YAML-based with sensible defaults
- Testing: Integration tests via pipeline smoke test (--quick flag)
- Docstrings: Only where logic isn't self-evident
- Imports: stdlib → third-party → local, sorted alphabetically

## Directory Structure Template
```
Panacea/
├── .github/
│   ├── workflows/
│   │   ├── deploy-webapp.yml        # Frontend → GitHub Pages
│   │   ├── inference-server-a.yml   # Ping-pong server A
│   │   ├── inference-server-b.yml   # Ping-pong server B
│   │   ├── train.yml                # Model training
│   │   └── claude.yml               # Claude Code integration
│   └── CODEOWNERS
├── src/
│   ├── data/                        # Dataset adapters, schema, augmentations
│   ├── model/                       # Baselines, classical ML, deep learning
│   ├── evaluation/                  # Metrics, fairness, robustness
│   └── utils/                       # Model hub, config, helpers
├── app/                             # FastAPI backend
│   └── main.py
├── webapp-react/                    # React 19 frontend
├── scripts/                         # Training, evaluation, benchmarking
├── configs/                         # YAML configuration
├── notebooks/                       # EDA, demos, experiments
├── models/                          # Trained artifacts (gitignored)
├── results/                         # Evaluation outputs (gitignored)
├── data/                            # Raw data (gitignored)
├── Dockerfile
├── Dockerfile.gpu
├── Makefile
├── requirements.txt
├── requirements-inference.txt
├── CLAUDE.md                        # This file
├── PLAN.md                          # Technical specification
└── README.md                        # Project overview
```

## ESA Kelvins CDM Dataset Schema Reference
**Source**: Zenodo (https://zenodo.org/records/4463683) -- 221MB zip
**Train**: 162,634 rows, 13,154 events | **Test**: 24,484 rows, 2,167 events
**Target column**: `risk` (log10 collision probability)
**Event grouping**: `event_id`
**Time ordering**: `time_to_tca` (days before closest approach, decreasing per event)

**Key columns** (103 total, all numerical except `c_object_type`):
- `event_id`, `time_to_tca`, `mission_id`, `risk`
- `miss_distance` (meters), `relative_speed` (m/s)
- `relative_position_{r,t,n}` (radial/transverse/normal, meters)
- `relative_velocity_{r,t,n}` (m/s)
- `max_risk_estimate`, `max_risk_scaling`
- `c_object_type` (categorical: debris type)
- `geocentric_latitude`, `azimuth`, `elevation` (degrees)
- `F10`, `AP`, `F3M`, `SSN` (space weather indices)

**Per-object columns** (prefixed `c_` for chaser/debris, `t_` for target/satellite):
- `x_sigma_{r,n,t}` -- position covariance std devs (m)
- `x_sigma_{rdot,ndot,tdot}` -- velocity covariance std devs (m/s)
- `x_position_covariance_det` -- covariance determinant
- `x_cn_r`, `x_cn_t`, `x_cndot_*`, `x_crdot_*`, `x_ctdot_*` -- correlations
- `x_h_apo`, `x_h_per` -- apogee/perigee altitude (km)
- `x_j2k_sma` -- semi-major axis (km)
- `x_j2k_inc` -- inclination (degrees)
- `x_ecc` -- eccentricity
- `x_span` -- object physical size (m)
- `x_cd_area_over_mass`, `x_cr_area_over_mass` -- ballistic coefficients
- `x_rcs_estimate` -- radar cross-section (m^2)
- `x_sedr` -- energy dissipation rate (W/kg)
- `x_actual_od_span`, `x_recommended_od_span` -- OD intervals (days)
- `x_obs_available`, `x_obs_used` -- observation counts
- `x_time_lastob_start`, `x_time_lastob_end` -- observation timing (days)
- `x_weighted_rms`, `x_residuals_accepted` -- orbit fit quality

## Current Status & Resume Notes (2026-02-07)

### Git State
- **Branch**: `main` (feature/3d-globe already merged)
- All webapp-react/ files are committed
- No remote repository set up yet

### Webapp 3D Globe — WHITE SCREEN BUG (UNRESOLVED)
The 3D Earth globe renders briefly then crashes to a white screen when satellite data arrives from CelesTrak. The error boundary does NOT catch it, meaning it's likely a WebGL context loss rather than a React error.

**What has been tried (all failed to fix it):**
1. Switched from InstancedMesh (sphere geometry per object) to Points + BufferGeometry (single draw call, Float32Array positions/colors)
2. Fixed InstancedMesh buffer to constant MAX_INSTANCES=25000 to prevent mesh recreation
3. Added NaN/Infinity filtering in `propagateSatellite()` — rejects bad TLEs, decayed orbits, positions outside 6371-100000 km
4. Added React ErrorBoundary around Canvas (crash bypasses it — not a React error)
5. Reduced default enabled groups to only stations (~500 objects, all debris disabled)
6. Chunked async propagation with setTimeout(0) yields between 500-object batches
7. Adaptive update interval (2-10s based on object count)
8. NORAD_CAT_ID deduplication across groups
9. Moved instance matrix updates from useFrame (every frame) to useEffect (on data change only)

**What to try next:**
- Open Chrome DevTools Console BEFORE loading the page to capture the actual error/stack trace
- Check if it's a WebGL context lost event (`canvas.addEventListener('webglcontextlost')`)
- Try rendering with satellites=[] permanently (hardcode) to confirm the Earth+atmosphere+stars render stably alone — if they do, the bug is in SatelliteLayer; if not, it's in Globe.tsx (texture loading, shaders, etc.)
- Check if the Atmosphere component's custom fragment shader is crashing WebGL on this GPU
- Try `<Canvas gl={{ antialias: false, powerPreference: 'high-performance' }}>` to reduce GPU load
- Consider the Stars component from drei — 5000 star particles might compound with satellite points
- Check if Suspense + useLoader for textures is causing a race condition with the satellite data arriving
- As a nuclear option: render Earth as a solid color sphere (no textures/shaders) to isolate whether textures or satellites cause the crash

**Key files for debugging:**
- `webapp-react/src/components/Globe.tsx` — Canvas, Earth textures, Atmosphere shader, Stars
- `webapp-react/src/components/SatelliteLayer.tsx` — Points renderer (was InstancedMesh)
- `webapp-react/src/hooks/useSatellites.ts` — Fetch + propagation logic
- `webapp-react/src/lib/orbital.ts` — SGP4 propagation with NaN filtering
- `webapp-react/src/lib/types.ts` — OBJECT_GROUPS (only stations enabled)
- `webapp-react/src/App.tsx` — ErrorBoundary + Suspense

### Other Pending Work
- Download ESA Kelvins CDM dataset (221MB from Zenodo — deferred, Zenodo was slow)
- Complete EDA notebooks once CDM data is available
- Build FastAPI backend (app/main.py)
- Build 3 ML models (baseline, XGBoost, PI-TFT)
- Set up GitHub remote and deployment workflows

## Key Lessons from SkinTag
1. **Embedding-based approach wins**: Extract embeddings from large pretrained model → train lightweight classifier on top. XGBoost on frozen embeddings often beats end-to-end fine-tuning.
2. **Field augmentations matter**: Training data is often clinical-quality; real-world photos are messy. Bridge that gap with noise, compression, lighting augmentations.
3. **Fairness is a feature, not an afterthought**: Build demographic-balanced sampling from day one. Report per-group metrics.
4. **Dual deployment**: HuggingFace Space (Gradio) for quick demo + React app for production-quality UX.
5. **Inference-only requirements file**: Strip training dependencies for lighter deployment.
6. **Medical disclaimers are mandatory**: Every output needs a clear disclaimer. This is not optional.
7. **Three-tier model comparison tells a story**: Naive (why accuracy lies) → Classical (strong baseline) → Deep (marginal gains justify complexity).
8. **Knowledge distillation as future-proofing**: 200x compression with <0.5% performance loss enables mobile deployment.
